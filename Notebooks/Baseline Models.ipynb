{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7ab44d6",
   "metadata": {},
   "source": [
    "# Baseline Models\n",
    "We wish for our weather prediction model to be better than something simple.\n",
    "\n",
    "We will create two simple models here to benchmark the model we make later.\n",
    "\n",
    "The first will be just extending the last point in the series out across our prediction period.\n",
    "\n",
    "The second will be a basic RNN with no optimisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33985b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler#, Normalizer\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, LSTM, GRU, Dense, Dropout, LayerNormalization, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548af53",
   "metadata": {},
   "source": [
    "#### Import the data, format the date and split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b684d381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2014-10-16    13.8\n",
       "2014-10-17    15.1\n",
       "2014-10-18    17.0\n",
       "2014-10-19    16.1\n",
       "2014-10-20    13.1\n",
       "Name: temp, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import data\n",
    "df = pd.read_csv('../Data/weather_data.csv')\n",
    "\n",
    "#get temp and time\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format='%d/%m/%Y')\n",
    "df = df.set_index('datetime')\n",
    "\n",
    "#split final week for plotting. Validation data\n",
    "train_data = df['temp'].iloc[:-457]\n",
    "val_data = df['temp'].iloc[-457:-7]\n",
    "test_data = df['temp'].iloc[-7:]\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f0d215",
   "metadata": {},
   "source": [
    "#### Model 1: extend last value in sequence\n",
    "Yup, super simple. Lets just assume the temperature will never change\n",
    "\n",
    "Our later model will take in a sequence of values and then try to predict what the nect value will be. So we will set things up in a similar way here to keep things fair. \n",
    "\n",
    "Lets say the sequence length is 10 days and the 11th must be predicted.\n",
    "\n",
    "so for this model we will assume that the temperature on the 11th day is the same as the 10th. We will roll this forward across our validation set to get a baseline Mean Absolute Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d77d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 10\n",
    "\n",
    "val_generator = TimeseriesGenerator(data=val_data, targets=val_data, length=length, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f80ca82",
   "metadata": {},
   "source": [
    "Our input sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ac95ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.3,  6.5,  6.4, 10.8,  9.3,  6.8,  5.9,  5.3,  7.3,  6.4]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_generator[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5051a0",
   "metadata": {},
   "source": [
    "The next value in the series (what we need to predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d40688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_generator[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a384f9",
   "metadata": {},
   "source": [
    "So we're actually going to predict that the next value is **6.4.**\n",
    "\n",
    "This gives us an error of **-3.5**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8398e2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.5])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_generator[0][0][:,-1] - val_generator[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a7c340",
   "metadata": {},
   "source": [
    "So lets do this across the whole validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e93e28e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_preds = len(val_data) - length\n",
    "preds = []\n",
    "\n",
    "for i in range(num_preds):\n",
    "    preds.append(val_generator[i][0][:,-1][0])\n",
    "    \n",
    "preds = pd.Series(preds, index = val_data.index[length:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "45a5ba45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2020-02-22    6.4\n",
       "2020-02-23    9.9\n",
       "2020-02-24    9.5\n",
       "2020-02-25    8.4\n",
       "2020-02-26    5.2\n",
       "             ... \n",
       "2021-05-02    6.9\n",
       "2021-05-03    8.2\n",
       "2021-05-04    8.5\n",
       "2021-05-05    8.5\n",
       "2021-05-06    5.7\n",
       "Length: 440, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cb5ae3",
   "metadata": {},
   "source": [
    "All we've really done is shifted the series back by one step. I just wanted to show off the TimeSeriesGenerator class.\n",
    "Lets Calculate the mean absolute error on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10dff3d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.614545454545455"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds - val_data).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06a31f1",
   "metadata": {},
   "source": [
    "**1.61C** is the average error with this rule of thumb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83039200",
   "metadata": {},
   "source": [
    "#### Model 2\n",
    "We'll be using Tensorflow 2 to make our optimised model later. Lets build a simple one now to see what our later tuning will have to beat.\n",
    "First we must scale our data so that it can be passed into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5e50170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(train_data.values.reshape(-1,1))\n",
    "train_scaled = scaler.transform(train_data.values.reshape(-1,1))\n",
    "validation_scaled = scaler.transform(val_data.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fa16d9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data generator \n",
    "generator = TimeseriesGenerator(data=train_scaled, targets=train_scaled, length=length, batch_size=1)\n",
    "val_generator = TimeseriesGenerator(data=validation_scaled, targets=validation_scaled, length=length, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230cc399",
   "metadata": {},
   "source": [
    "Lets use a callback to stop the model from overfitting. Let's use another to save the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b568e541",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callbacks\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
    "model_cp = ModelCheckpoint(filepath='models/baseline_rnn.h5', save_weights_only=False, monitor='val_mae', save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cad76b",
   "metadata": {},
   "source": [
    "#### Basic Sequential LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85fdbe1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(units=50, activation='tanh', input_shape=(length, 1)))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48bddc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 50)                10400     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 10,451\n",
      "Trainable params: 10,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db50651",
   "metadata": {},
   "source": [
    "Compile and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d5d8f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1933/1933 [==============================] - 5s 3ms/step - loss: 0.0074 - mae: 0.0671 - val_loss: 0.0073 - val_mae: 0.0675\n",
      "Epoch 2/200\n",
      "1933/1933 [==============================] - 5s 3ms/step - loss: 0.0049 - mae: 0.0556 - val_loss: 0.0043 - val_mae: 0.0505\n",
      "Epoch 3/200\n",
      "1933/1933 [==============================] - 5s 3ms/step - loss: 0.0042 - mae: 0.0512 - val_loss: 0.0044 - val_mae: 0.0515\n",
      "Epoch 4/200\n",
      "1933/1933 [==============================] - 5s 3ms/step - loss: 0.0042 - mae: 0.0511 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 5/200\n",
      "1933/1933 [==============================] - 5s 3ms/step - loss: 0.0041 - mae: 0.0505 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 6/200\n",
      "1933/1933 [==============================] - 5s 3ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 7/200\n",
      "1933/1933 [==============================] - 5s 3ms/step - loss: 0.0041 - mae: 0.0504 - val_loss: 0.0042 - val_mae: 0.0505\n",
      "Epoch 8/200\n",
      "1933/1933 [==============================] - 5s 3ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0053 - val_mae: 0.0572\n",
      "Epoch 9/200\n",
      "1933/1933 [==============================] - 5s 3ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0041 - val_mae: 0.0496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ade6515be0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "model.fit(generator, validation_data=val_generator, epochs=200, callbacks=[early_stop, model_cp])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657f5ad5",
   "metadata": {},
   "source": [
    "Load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66c1be37",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = tf.keras.models.load_model('models/baseline_rnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeeb386",
   "metadata": {},
   "source": [
    "Get predictions and transform the back to orginal units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bbcb7ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = baseline_model.predict(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0fb81031",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.Series(scaler.inverse_transform(preds).round(1)[:,0],\n",
    "                  index = val_data[length:].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b31b9c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2020-02-22    6.4\n",
       "2020-02-23    9.8\n",
       "2020-02-24    8.7\n",
       "2020-02-25    8.2\n",
       "2020-02-26    5.5\n",
       "             ... \n",
       "2021-05-02    7.1\n",
       "2021-05-03    8.3\n",
       "2021-05-04    8.3\n",
       "2021-05-05    8.3\n",
       "2021-05-06    5.9\n",
       "Length: 440, dtype: float32"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66a1eca",
   "metadata": {},
   "source": [
    "Those preds look slightly different to what we had before. Lets see what the MAE is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "200eff77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5456818160482424"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(preds - val_data).abs().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2c4b43",
   "metadata": {},
   "source": [
    "**1.54C** is our MAE. Granted there is a little bias here due to us guiding the training off the back of the validation set.\n",
    "So it might be fiar to assume that this model did not do much more than projecting the last value forward like in model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa9b70c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7428f7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1534ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
