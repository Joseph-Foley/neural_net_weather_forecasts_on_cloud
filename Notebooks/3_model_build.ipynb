{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aFh4SSnScgyT"
   },
   "source": [
    "# Model Build\n",
    "Building and testing models notebook for Google Colab.\n",
    "\n",
    "The daily temperature from the weather API will be used as our training data.\n",
    "\n",
    "I have built a class that will allow us to build a recurrent neural network (TF2). One can easily play around with the hyper parameters of through this class, including the type of recurrent layer (GRU or LSTM) and even the number of recurrent layers the model will have.\n",
    "\n",
    "Two functions are written to search through the possible hyper parameters. From these we can train and select the most optimised model.\n",
    "\n",
    "Lastly the hundreds of models genereated will be analysed. the best model will be recreated and its predictions plotted against a test set.\n",
    "\n",
    "Be sure to switch to GPU in the run time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 168,
     "status": "ok",
     "timestamp": 1621886199593,
     "user": {
      "displayName": "1990JAF",
      "photoUrl": "",
      "userId": "13601147066600634770"
     },
     "user_tz": -60
    },
    "id": "41wVApIlcCcg",
    "outputId": "0751d9fc-afc3-4eb8-8525-a58ed2474ebc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "\n",
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 650,
     "status": "ok",
     "timestamp": 1621886031308,
     "user": {
      "displayName": "1990JAF",
      "photoUrl": "",
      "userId": "13601147066600634770"
     },
     "user_tz": -60
    },
    "id": "HteX1ohWdC35",
    "outputId": "3e091663-7047-43d8-ecbd-324523a4a1f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results_table_1621536110.csv  results_table_1621765059.csv   temp_model.h5\n",
      "results_table_1621583745.csv  results_table_temp.csv\t     weather_data.csv\n",
      "results_table_1621688232.csv  results_table_temp_smooth.csv\n"
     ]
    }
   ],
   "source": [
    "#my file path to data on Gdrive\n",
    "! ls drive/MyDrive/0_neural_net_weather_forecasts_on_cloud/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1621886034694,
     "user": {
      "displayName": "1990JAF",
      "photoUrl": "",
      "userId": "13601147066600634770"
     },
     "user_tz": -60
    },
    "id": "D978SAl6Easn"
   },
   "outputs": [],
   "source": [
    "os.chdir('drive/MyDrive/0_neural_net_weather_forecasts_on_cloud/Data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9Pmh4OhDNeu"
   },
   "source": [
    "## Load data and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1621886040849,
     "user": {
      "displayName": "1990JAF",
      "photoUrl": "",
      "userId": "13601147066600634770"
     },
     "user_tz": -60
    },
    "id": "HlFbPxxnc8nm"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('weather_data.csv')\n",
    "\n",
    "#get temp and time\n",
    "df['datetime'] = pd.to_datetime(df['datetime'], format='%d/%m/%Y')\n",
    "df = df.set_index('datetime')\n",
    "\n",
    "temp = df['temp']\n",
    "\n",
    "#split data (Save a week for testing. Train and Validation made in class)\n",
    "temp_train = temp.iloc[:-7]\n",
    "temp_test = temp.iloc[-7:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "618XE3dIA99N"
   },
   "source": [
    "##Define the model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 457,
     "status": "ok",
     "timestamp": 1621886416076,
     "user": {
      "displayName": "1990JAF",
      "photoUrl": "",
      "userId": "13601147066600634770"
     },
     "user_tz": -60
    },
    "id": "0iLf4dZsdRLY"
   },
   "outputs": [],
   "source": [
    "class BuildModel():\n",
    "    \"\"\"\n",
    "    Build a model. Arguments allow one to customise the hyper parameters\n",
    "    ATTRIBUTES :- \n",
    "    length - number of steps in time sequence to feed the rnn\n",
    "    layers_num - number of rnn layers in model (capped at 3)\n",
    "    layers_type - select \"LSTM\" or \"GRU\"\n",
    "    units - number of units in rnn layers\n",
    "    num_step_preds - number of steps/days in time to predict\n",
    "    dropout - dropout % to be applied to rnn units\n",
    "    batch_size - number of samples to feed model at a time.\n",
    "    patience - how many epochs to wait before stopping model after finding good score.\n",
    "    model_name - file name of model we save. must end in \".h5\" eg 'temp_model.h5'\n",
    "    \"\"\"\n",
    "    def __init__(self, model_name, length=10, layers_num=1, layers_type='LSTM',\\\n",
    "                 units=50, num_step_preds=1, dropout=0.0, epochs=8,\\\n",
    "                 batch_size=1, patience=5):\n",
    "        \n",
    "        #assertions for input\n",
    "        assert 0 < layers_num < 4, \"1 <= layers_num <= 3\"\n",
    "        assert layers_type in ['LSTM', 'GRU'], \"layers_type is LSTM or GRU\"\n",
    "        assert 0 <= dropout < 1, \"dropout must be float < 1\"\n",
    "        assert model_name[-3:] == '.h5', \"End model_name with '.h5'\"\n",
    "        \n",
    "        #initialise\n",
    "        self.length = length\n",
    "        self.layers_num = layers_num\n",
    "        self.layers_type = layers_type\n",
    "        self.units = units\n",
    "        self.num_step_preds = num_step_preds\n",
    "        self.dropout = dropout\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.model_name = model_name\n",
    "        self.n_features = 1\n",
    "        \n",
    "        #callbacks\n",
    "        self.callbacks =[EarlyStopping(monitor='val_loss', patience=patience),\\\n",
    "                         ModelCheckpoint(self.model_name, monitor='val_loss',\\\n",
    "                                         save_best_only=True)]\n",
    "        \n",
    "        #BUILD MODEL\n",
    "        ##inputs\n",
    "        self.model = Sequential()\n",
    "        self.model.add(InputLayer(input_shape=(self.length, self.n_features)))\n",
    "        \n",
    "        ##add extra layers as required (or not if layers_num = 1)\n",
    "        for i in range(layers_num - 1):\n",
    "            self.model.add(eval('{}(units={}, dropout={}, return_sequences=True)'\\\n",
    "                .format(self.layers_type, self.units, self.dropout)))\n",
    "                \n",
    "        ##closing rnn layer (do not return squences)\n",
    "        self.model.add(eval('{}(units={}, dropout={})'\\\n",
    "                .format(self.layers_type, self.units, self.dropout)))\n",
    "            \n",
    "        ##Dense output\n",
    "        self.model.add(Dense(units=self.num_step_preds))\n",
    "                       \n",
    "        #compile model\n",
    "        self.model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    \n",
    "    def setupData(self, series, val_days=450):\n",
    "        \"\"\"\n",
    "        splits data, scales data, creates generators for the model\n",
    "        \"\"\"\n",
    "        assert val_days > self.length , \"val_days must exceed length\"\n",
    "        \n",
    "        #split data into train and validation\n",
    "        self.train = series.iloc[:-val_days]\n",
    "        self.validation = series.iloc[-val_days:]\n",
    "        \n",
    "        #scale data for neural network suitability\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.scaler.fit(self.train.values.reshape(-1,1))\n",
    "        \n",
    "        self.train_scaled = \\\n",
    "            self.scaler.transform(self.train.values.reshape(-1,1))\n",
    "        \n",
    "        self.validation_scaled = \\\n",
    "             self.scaler.transform(self.validation.values.reshape(-1,1))\n",
    "        \n",
    "        #create time series generators\n",
    "        self.generator = \\\n",
    "             TimeseriesGenerator(data=self.train_scaled,\\\n",
    "                                 targets=self.train_scaled,\\\n",
    "                                 length=self.length,\\\n",
    "                                 batch_size=self.batch_size)\n",
    "                 \n",
    "        self.val_generator = \\\n",
    "             TimeseriesGenerator(data=self.validation_scaled,\\\n",
    "                                 targets=self.validation_scaled,\\\n",
    "                                 length=self.length,\\\n",
    "                                 batch_size=self.batch_size)\n",
    "\n",
    "    def fitModel(self):\n",
    "        \"\"\"\n",
    "        Fits the model on your generators for training and validation sets.\n",
    "        EarlyStopping call back ends training if val_loss doesnt improve.\n",
    "        Record epoch metrics in a DataFrame.\n",
    "        \"\"\"\n",
    "        self.model.fit(self.generator, validation_data=self.val_generator,\\\n",
    "                       epochs=self.epochs, callbacks=self.callbacks)\n",
    "            \n",
    "        self.history = pd.DataFrame(self.model.history.history)\n",
    "        \n",
    "    def loadModel(self):\n",
    "        \"\"\"\n",
    "        Load a model instead of fitting a new one (uses model_name)\n",
    "        \"\"\"\n",
    "        self.model = tf.keras.models.load_model(self.model_name)\n",
    "            \n",
    "    def predAhead(self, days, series=None):\n",
    "        \"\"\"\n",
    "        Predicts a number of days ahead set by the user. Input your own\n",
    "        series or dont if you want to predict off of the validation set.\n",
    "        \"\"\"\n",
    "        assert self.num_step_preds == 1,\\\n",
    "            \"sorry, function not yet available for multi step models\"\n",
    "        \n",
    "        #use end of the validation set to project forward if no series given\n",
    "        if series == None:\n",
    "            series = self.validation\n",
    "        \n",
    "        #get end of the series to plug into the model\n",
    "        assert len(series) >= self.length,\\\n",
    "            \"series must be at least {} days\".format(self.length)\n",
    "            \n",
    "        series_cut = series.iloc[-self.length:]\n",
    "        \n",
    "        #scale inputs to what model is expecting    \n",
    "        series_scaled = \\\n",
    "            self.scaler.transform(series_cut.values.reshape(-1,1))\n",
    "            \n",
    "        #predict ahead by appending predictions and removing first values\n",
    "        pred_series = series_scaled.reshape(1, self.length, self.n_features)\n",
    "        predictions = []\n",
    "        \n",
    "        for i in range(days):\n",
    "            pred = self.model.predict(pred_series)\n",
    "            pred_series = np.append(pred_series[:,1:,:], [pred], axis=1)\n",
    "            predictions.append(pred)\n",
    "            \n",
    "        #inverse scale back to original units\n",
    "        predictions = np.array(predictions)\n",
    "        predictions = self.scaler.inverse_transform(\\\n",
    "                           predictions.reshape(days, self.n_features))\\\n",
    "                          .round(1)\n",
    "        \n",
    "        #convert to pandas series\n",
    "        predictions = pd.Series(predictions.reshape(days))\n",
    "        predictions.index = self.validation.index[-days:] +\\\n",
    "                                 dt.timedelta(days=days)\n",
    "            \n",
    "        return predictions\n",
    "    \n",
    "    def plotPreds(self, predictions, test_series=None, run_up=None,\\\n",
    "                  ylabel='units'):\n",
    "        \"\"\"\n",
    "        plot the predictions of the model. plot them against another series\n",
    "        (test series). plot with with a run up leading to the pred period\n",
    "        (validation set).\n",
    "        \"\"\"\n",
    "        #set up figure\n",
    "        plt.figure(figsize=(10,6))\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlabel('datetime')\n",
    "        \n",
    "        #plot lines\n",
    "        if run_up is None:\n",
    "            run_up = self.validation[-7:]\n",
    "            \n",
    "        if test_series is not None:\n",
    "            plt.plot(pd.concat([run_up, test_series[:1]]))\n",
    "            plt.plot(test_series)\n",
    "            \n",
    "        else:\n",
    "            plt.plot(run_up)\n",
    "            \n",
    "        #plot points\n",
    "        plt.scatter(predictions.index, predictions, edgecolors='k',\\\n",
    "                    label='predictions', c='#2ca02c', s=64)\n",
    "            \n",
    "        if test_series is not None:\n",
    "            plt.scatter(test_series.index, test_series, marker='X',\\\n",
    "                        edgecolors='k', label='test_data', c='#ff7f0e', s=200)\n",
    "                \n",
    "        plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "enCjdIxABB9a"
   },
   "source": [
    "##Define Functions for searching over the model's hyperparameters\n",
    "NOTE: Requires Pandas 1.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pmqzpncSCti5"
   },
   "outputs": [],
   "source": [
    "#! pip install pandas==1.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ds7gfFqTdwG1"
   },
   "outputs": [],
   "source": [
    "\n",
    "def gridTableGen(length: list, layers_num: list, layers_type: list,\\\n",
    "               units: list,  dropout: list):\n",
    "    \"\"\"returns table of every combo for the hyperparameters\"\"\"\n",
    "    \n",
    "    #get cross joins to acquire every combination\n",
    "    grid_table = pd.DataFrame(length).merge(\\\n",
    "                 pd.DataFrame(layers_num), how='cross').merge(\\\n",
    "                 pd.DataFrame(layers_type), how='cross').merge(\\\n",
    "                 pd.DataFrame(units), how='cross').merge(\\\n",
    "                 pd.DataFrame(dropout), how='cross')\n",
    "                                                     \n",
    "    grid_table.columns = \\\n",
    "        ['length', 'layers_num', 'layers_type', 'units', 'dropout']\n",
    "        \n",
    "    return grid_table\n",
    "\n",
    "\n",
    "\n",
    "def gridSearch(grid_table, data):\n",
    "    \"\"\"searches through hyperparameters in grid_table to determine optimium model\"\"\"\n",
    "    #record time for file_name\n",
    "    time_now = str(round(time.time()))\n",
    "        \n",
    "    #make results table to append results onto\n",
    "    results_cols =\\\n",
    "        pd.DataFrame(columns=['loss', 'mae', 'val_loss', 'val_mae', 'epochs'])\n",
    "        \n",
    "    results_table = pd.concat([grid_table, results_cols], axis=1)\n",
    "    \n",
    "    #iterate through the table and fit the models\n",
    "    for i, row in grid_table.iterrows():\n",
    "        #input hyperparameters\n",
    "        print('\\nNow Training ({})\\n{}'.format(i, row.to_dict()))\n",
    "        grid_mod = \\\n",
    "            BuildModel(length=row['length'], layers_num=row['layers_num'],\\\n",
    "                       layers_type=row['layers_type'],units=row['units'],\\\n",
    "                       num_step_preds=1, dropout=row['dropout'], epochs=2,\\\n",
    "                       batch_size=10, patience=5)\n",
    "        \n",
    "        #setup data and train the model\n",
    "        grid_mod.setupData(data)\n",
    "        grid_mod.fitModel()\n",
    "        \n",
    "        #find best epoch (val_mae)\n",
    "        hist = grid_mod.history\n",
    "        best_epoch = hist[hist['val_mae'] == hist['val_mae'].min()]\\\n",
    "                     .iloc[:1]\n",
    "        \n",
    "        #update results table\n",
    "        results_table.loc[i, ['loss', 'mae', 'val_loss', 'val_mae']] =\\\n",
    "            best_epoch.values[0].round(4)\n",
    "        \n",
    "        results_table.loc[i, 'epochs'] = best_epoch.index[0]\n",
    "        \n",
    "        #save to drive\n",
    "        results_table.to_csv('results_table_' + time_now + '.csv', index=False)\n",
    "        \n",
    "    return results_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BDvVUw88BdGc"
   },
   "source": [
    "##Use functions and class to optimise a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D504_ECw0s_h",
    "outputId": "4e219b25-105b-48c6-933a-bcade5955501"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0041 - mae: 0.0504 - val_loss: 0.0056 - val_mae: 0.0610\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0470 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0046 - val_mae: 0.0548\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0041 - mae: 0.0502 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0041 - mae: 0.0499 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0041 - val_mae: 0.0514\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0043 - val_mae: 0.0524\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0043 - mae: 0.0512 - val_loss: 0.0042 - val_mae: 0.0502\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0042 - val_mae: 0.0520\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0042 - val_mae: 0.0500\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0034 - mae: 0.0455 - val_loss: 0.0039 - val_mae: 0.0493\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0498 - val_loss: 0.0041 - val_mae: 0.0512\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0041 - val_mae: 0.0507\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0038 - val_mae: 0.0486\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0036 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0505\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0041 - val_mae: 0.0490\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0041 - mae: 0.0501 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0034 - mae: 0.0471 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0508\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0041 - val_mae: 0.0493\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0488\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0041 - val_mae: 0.0512\n",
      "Epoch 54/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0493\n",
      "Epoch 55/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 56/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0040 - val_mae: 0.0497\n",
      "Epoch 57/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0041 - val_mae: 0.0493\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'GRU', 'units': 80, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 4s 10ms/step - loss: 0.0299 - mae: 0.1288 - val_loss: 0.0141 - val_mae: 0.0958\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0134 - mae: 0.0923 - val_loss: 0.0100 - val_mae: 0.0782\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0115 - mae: 0.0841 - val_loss: 0.0094 - val_mae: 0.0756\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0098 - mae: 0.0787 - val_loss: 0.0096 - val_mae: 0.0774\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0099 - mae: 0.0784 - val_loss: 0.0122 - val_mae: 0.0880\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0087 - mae: 0.0730 - val_loss: 0.0120 - val_mae: 0.0874\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0088 - mae: 0.0731 - val_loss: 0.0099 - val_mae: 0.0785\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0091 - mae: 0.0763 - val_loss: 0.0167 - val_mae: 0.1025\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0091 - mae: 0.0753 - val_loss: 0.0124 - val_mae: 0.0882\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0079 - mae: 0.0694 - val_loss: 0.0180 - val_mae: 0.1097\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0081 - mae: 0.0705 - val_loss: 0.0141 - val_mae: 0.0962\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0074 - mae: 0.0678 - val_loss: 0.0147 - val_mae: 0.0989\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0079 - mae: 0.0687 - val_loss: 0.0149 - val_mae: 0.1000\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0067 - mae: 0.0632 - val_loss: 0.0192 - val_mae: 0.1155\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0072 - mae: 0.0668 - val_loss: 0.0168 - val_mae: 0.1066\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0063 - mae: 0.0632 - val_loss: 0.0147 - val_mae: 0.0989\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0068 - mae: 0.0644 - val_loss: 0.0202 - val_mae: 0.1178\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0068 - mae: 0.0649 - val_loss: 0.0219 - val_mae: 0.1238\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0070 - mae: 0.0662 - val_loss: 0.0223 - val_mae: 0.1261\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0062 - mae: 0.0619 - val_loss: 0.0166 - val_mae: 0.1067\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0062 - mae: 0.0623 - val_loss: 0.0140 - val_mae: 0.0977\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0064 - mae: 0.0624 - val_loss: 0.0168 - val_mae: 0.1082\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0059 - mae: 0.0607 - val_loss: 0.0184 - val_mae: 0.1135\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'GRU', 'units': 80, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 4s 10ms/step - loss: 0.0656 - mae: 0.1864 - val_loss: 0.0211 - val_mae: 0.1168\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0194 - mae: 0.1090 - val_loss: 0.0133 - val_mae: 0.0914\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0136 - mae: 0.0940 - val_loss: 0.0157 - val_mae: 0.0996\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0125 - mae: 0.0885 - val_loss: 0.0245 - val_mae: 0.1254\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0116 - mae: 0.0841 - val_loss: 0.0130 - val_mae: 0.0901\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0112 - mae: 0.0842 - val_loss: 0.0223 - val_mae: 0.1206\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0107 - mae: 0.0811 - val_loss: 0.0296 - val_mae: 0.1406\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0104 - mae: 0.0800 - val_loss: 0.0527 - val_mae: 0.1929\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0112 - mae: 0.0842 - val_loss: 0.0467 - val_mae: 0.1808\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0091 - mae: 0.0755 - val_loss: 0.0528 - val_mae: 0.1965\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0082 - mae: 0.0722 - val_loss: 0.0579 - val_mae: 0.2033\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0087 - mae: 0.0730 - val_loss: 0.0462 - val_mae: 0.1807\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0077 - mae: 0.0687 - val_loss: 0.0464 - val_mae: 0.1846\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0087 - mae: 0.0732 - val_loss: 0.0528 - val_mae: 0.1949\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0089 - mae: 0.0739 - val_loss: 0.0537 - val_mae: 0.1979\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0077 - mae: 0.0702 - val_loss: 0.0441 - val_mae: 0.1765\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0081 - mae: 0.0712 - val_loss: 0.0488 - val_mae: 0.1898\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0076 - mae: 0.0689 - val_loss: 0.0661 - val_mae: 0.2268\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0070 - mae: 0.0655 - val_loss: 0.0652 - val_mae: 0.2230\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0079 - mae: 0.0692 - val_loss: 0.0518 - val_mae: 0.1952\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0066 - mae: 0.0635 - val_loss: 0.0536 - val_mae: 0.1995\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0073 - mae: 0.0661 - val_loss: 0.0495 - val_mae: 0.1941\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0074 - mae: 0.0675 - val_loss: 0.0563 - val_mae: 0.2041\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0072 - mae: 0.0665 - val_loss: 0.0604 - val_mae: 0.2146\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0067 - mae: 0.0641 - val_loss: 0.0633 - val_mae: 0.2212\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'GRU', 'units': 160, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 4s 10ms/step - loss: 0.0331 - mae: 0.1208 - val_loss: 0.0072 - val_mae: 0.0665\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0059 - mae: 0.0615 - val_loss: 0.0061 - val_mae: 0.0608\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0051 - mae: 0.0570 - val_loss: 0.0052 - val_mae: 0.0560\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0042 - mae: 0.0507 - val_loss: 0.0046 - val_mae: 0.0528\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0042 - mae: 0.0503 - val_loss: 0.0046 - val_mae: 0.0517\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0493 - val_loss: 0.0047 - val_mae: 0.0550\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0043 - val_mae: 0.0521\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0042 - val_mae: 0.0496\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0491 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0485\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0041 - val_mae: 0.0508\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0041 - mae: 0.0504 - val_loss: 0.0047 - val_mae: 0.0549\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0041 - val_mae: 0.0508\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0041 - val_mae: 0.0510\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0039 - val_mae: 0.0492\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0479 - val_loss: 0.0042 - val_mae: 0.0498\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0042 - val_mae: 0.0498\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0043 - val_mae: 0.0526\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0041 - val_mae: 0.0496\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0049 - val_mae: 0.0569\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0494\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0502\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0047 - val_mae: 0.0555\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0041 - mae: 0.0501 - val_loss: 0.0038 - val_mae: 0.0486\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0034 - mae: 0.0458 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0461 - val_loss: 0.0039 - val_mae: 0.0494\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0045 - val_mae: 0.0520\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0040 - val_mae: 0.0500\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0040 - val_mae: 0.0507\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0038 - val_mae: 0.0488\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0041 - val_mae: 0.0511\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0038 - val_mae: 0.0478\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0038 - val_mae: 0.0482\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0041 - val_mae: 0.0509\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 54/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 55/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0496\n",
      "Epoch 56/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 57/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 58/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 59/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0041 - val_mae: 0.0496\n",
      "Epoch 60/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0487 - val_loss: 0.0043 - val_mae: 0.0525\n",
      "Epoch 61/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 62/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 63/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0469 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 64/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0034 - mae: 0.0462 - val_loss: 0.0041 - val_mae: 0.0497\n",
      "Epoch 65/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0038 - val_mae: 0.0480\n",
      "Epoch 66/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0038 - val_mae: 0.0486\n",
      "Epoch 67/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0042 - val_mae: 0.0520\n",
      "Epoch 68/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0038 - val_mae: 0.0480\n",
      "Epoch 69/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 70/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 71/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0038 - val_mae: 0.0479\n",
      "Epoch 72/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0041 - val_mae: 0.0493\n",
      "Epoch 73/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0034 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0477\n",
      "Epoch 74/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 75/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0038 - val_mae: 0.0477\n",
      "Epoch 76/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 77/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0503\n",
      "Epoch 78/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0038 - val_mae: 0.0476\n",
      "Epoch 79/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 80/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 81/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 82/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 83/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0044 - val_mae: 0.0513\n",
      "Epoch 84/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 85/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0038 - val_mae: 0.0484\n",
      "Epoch 86/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 87/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 88/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0038 - val_mae: 0.0480\n",
      "Epoch 89/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0032 - mae: 0.0447 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 90/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0040 - val_mae: 0.0500\n",
      "Epoch 91/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0038 - val_mae: 0.0485\n",
      "Epoch 92/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0038 - val_mae: 0.0475\n",
      "Epoch 93/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 0.0038 - val_mae: 0.0482\n",
      "Epoch 94/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0460 - val_loss: 0.0038 - val_mae: 0.0478\n",
      "Epoch 95/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0038 - val_mae: 0.0484\n",
      "Epoch 96/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0034 - mae: 0.0450 - val_loss: 0.0037 - val_mae: 0.0471\n",
      "Epoch 97/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0041 - val_mae: 0.0505\n",
      "Epoch 98/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 99/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0038 - val_mae: 0.0478\n",
      "Epoch 100/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0040 - val_mae: 0.0484\n",
      "Epoch 101/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 102/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0041 - val_mae: 0.0498\n",
      "Epoch 103/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0038 - val_mae: 0.0477\n",
      "Epoch 104/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0048 - val_mae: 0.0556\n",
      "Epoch 105/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 106/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 107/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 108/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0040 - val_mae: 0.0502\n",
      "Epoch 109/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 110/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 111/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0038 - val_mae: 0.0479\n",
      "Epoch 112/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 113/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0038 - val_mae: 0.0476\n",
      "Epoch 114/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0042 - val_mae: 0.0499\n",
      "Epoch 115/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0478\n",
      "Epoch 116/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0042 - val_mae: 0.0510\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'GRU', 'units': 160, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 4s 11ms/step - loss: 0.0264 - mae: 0.1270 - val_loss: 0.0095 - val_mae: 0.0762\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0111 - mae: 0.0844 - val_loss: 0.0097 - val_mae: 0.0771\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0105 - mae: 0.0813 - val_loss: 0.0105 - val_mae: 0.0811\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0095 - mae: 0.0778 - val_loss: 0.0094 - val_mae: 0.0756\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0098 - mae: 0.0769 - val_loss: 0.0098 - val_mae: 0.0781\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0092 - mae: 0.0739 - val_loss: 0.0153 - val_mae: 0.0996\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0095 - mae: 0.0765 - val_loss: 0.0105 - val_mae: 0.0803\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0092 - mae: 0.0764 - val_loss: 0.0155 - val_mae: 0.1011\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0075 - mae: 0.0682 - val_loss: 0.0142 - val_mae: 0.0952\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0081 - mae: 0.0711 - val_loss: 0.0162 - val_mae: 0.1049\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0073 - mae: 0.0664 - val_loss: 0.0205 - val_mae: 0.1185\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0068 - mae: 0.0646 - val_loss: 0.0171 - val_mae: 0.1080\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0069 - mae: 0.0649 - val_loss: 0.0183 - val_mae: 0.1116\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0068 - mae: 0.0652 - val_loss: 0.0188 - val_mae: 0.1138\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0063 - mae: 0.0625 - val_loss: 0.0173 - val_mae: 0.1093\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0065 - mae: 0.0645 - val_loss: 0.0154 - val_mae: 0.1026\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0073 - mae: 0.0678 - val_loss: 0.0163 - val_mae: 0.1058\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0062 - mae: 0.0624 - val_loss: 0.0217 - val_mae: 0.1251\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0061 - mae: 0.0616 - val_loss: 0.0169 - val_mae: 0.1090\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0057 - mae: 0.0592 - val_loss: 0.0118 - val_mae: 0.0892\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0062 - mae: 0.0625 - val_loss: 0.0229 - val_mae: 0.1303\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0059 - mae: 0.0608 - val_loss: 0.0203 - val_mae: 0.1208\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0059 - mae: 0.0614 - val_loss: 0.0154 - val_mae: 0.1040\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0063 - mae: 0.0625 - val_loss: 0.0186 - val_mae: 0.1150\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'GRU', 'units': 160, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 3s 11ms/step - loss: 0.0357 - mae: 0.1401 - val_loss: 0.0122 - val_mae: 0.0869\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0169 - mae: 0.1026 - val_loss: 0.0190 - val_mae: 0.1112\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0152 - mae: 0.0970 - val_loss: 0.0149 - val_mae: 0.0967\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0134 - mae: 0.0918 - val_loss: 0.0221 - val_mae: 0.1191\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0122 - mae: 0.0874 - val_loss: 0.0240 - val_mae: 0.1256\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0099 - mae: 0.0769 - val_loss: 0.0420 - val_mae: 0.1736\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0093 - mae: 0.0758 - val_loss: 0.0611 - val_mae: 0.2099\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0095 - mae: 0.0775 - val_loss: 0.0497 - val_mae: 0.1885\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0094 - mae: 0.0772 - val_loss: 0.0485 - val_mae: 0.1870\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0077 - mae: 0.0681 - val_loss: 0.0553 - val_mae: 0.2018\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0083 - mae: 0.0720 - val_loss: 0.0643 - val_mae: 0.2161\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0078 - mae: 0.0695 - val_loss: 0.0530 - val_mae: 0.1994\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0072 - mae: 0.0661 - val_loss: 0.0642 - val_mae: 0.2204\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0081 - mae: 0.0714 - val_loss: 0.0592 - val_mae: 0.2098\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0075 - mae: 0.0682 - val_loss: 0.0620 - val_mae: 0.2171\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0074 - mae: 0.0682 - val_loss: 0.0713 - val_mae: 0.2356\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0079 - mae: 0.0694 - val_loss: 0.0566 - val_mae: 0.2058\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0076 - mae: 0.0682 - val_loss: 0.0646 - val_mae: 0.2233\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0072 - mae: 0.0672 - val_loss: 0.0592 - val_mae: 0.2138\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0074 - mae: 0.0679 - val_loss: 0.0620 - val_mae: 0.2169\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0075 - mae: 0.0684 - val_loss: 0.0709 - val_mae: 0.2336\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 10, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 3s 11ms/step - loss: 0.0512 - mae: 0.1699 - val_loss: 0.0112 - val_mae: 0.0833\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0081 - mae: 0.0700 - val_loss: 0.0088 - val_mae: 0.0740\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0070 - mae: 0.0653 - val_loss: 0.0093 - val_mae: 0.0777\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0067 - mae: 0.0651 - val_loss: 0.0085 - val_mae: 0.0723\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0058 - mae: 0.0594 - val_loss: 0.0089 - val_mae: 0.0762\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0065 - mae: 0.0640 - val_loss: 0.0076 - val_mae: 0.0695\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0062 - mae: 0.0623 - val_loss: 0.0083 - val_mae: 0.0720\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0062 - mae: 0.0618 - val_loss: 0.0074 - val_mae: 0.0679\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0056 - mae: 0.0586 - val_loss: 0.0071 - val_mae: 0.0668\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0055 - mae: 0.0587 - val_loss: 0.0074 - val_mae: 0.0678\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0059 - mae: 0.0596 - val_loss: 0.0068 - val_mae: 0.0654\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0057 - mae: 0.0596 - val_loss: 0.0071 - val_mae: 0.0666\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0050 - mae: 0.0563 - val_loss: 0.0065 - val_mae: 0.0642\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0054 - mae: 0.0585 - val_loss: 0.0064 - val_mae: 0.0635\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0056 - mae: 0.0599 - val_loss: 0.0073 - val_mae: 0.0684\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0049 - mae: 0.0556 - val_loss: 0.0062 - val_mae: 0.0624\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0049 - mae: 0.0545 - val_loss: 0.0061 - val_mae: 0.0619\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0051 - mae: 0.0564 - val_loss: 0.0060 - val_mae: 0.0614\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0047 - mae: 0.0546 - val_loss: 0.0059 - val_mae: 0.0606\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0047 - mae: 0.0546 - val_loss: 0.0064 - val_mae: 0.0634\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0052 - mae: 0.0568 - val_loss: 0.0057 - val_mae: 0.0594\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0046 - mae: 0.0548 - val_loss: 0.0055 - val_mae: 0.0582\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0047 - mae: 0.0548 - val_loss: 0.0054 - val_mae: 0.0577\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0044 - mae: 0.0522 - val_loss: 0.0056 - val_mae: 0.0591\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0044 - mae: 0.0522 - val_loss: 0.0055 - val_mae: 0.0587\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0044 - mae: 0.0534 - val_loss: 0.0049 - val_mae: 0.0548\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0043 - mae: 0.0516 - val_loss: 0.0051 - val_mae: 0.0554\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0046 - val_mae: 0.0530\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0041 - mae: 0.0510 - val_loss: 0.0045 - val_mae: 0.0529\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0044 - val_mae: 0.0521\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0046 - val_mae: 0.0520\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0042 - val_mae: 0.0502\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0483 - val_loss: 0.0042 - val_mae: 0.0505\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0037 - mae: 0.0468 - val_loss: 0.0043 - val_mae: 0.0505\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0041 - val_mae: 0.0498\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0041 - val_mae: 0.0497\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0043 - val_mae: 0.0520\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0041 - val_mae: 0.0503\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0464 - val_loss: 0.0042 - val_mae: 0.0506\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0456 - val_loss: 0.0041 - val_mae: 0.0500\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0042 - val_mae: 0.0497\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0476 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0460 - val_loss: 0.0043 - val_mae: 0.0520\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0044 - val_mae: 0.0513\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 54/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 55/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 56/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 57/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 58/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 59/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0041 - val_mae: 0.0504\n",
      "Epoch 60/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 61/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 62/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 63/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0042 - val_mae: 0.0512\n",
      "Epoch 64/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 65/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 66/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0042 - val_mae: 0.0513\n",
      "Epoch 67/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0040 - mae: 0.0494 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 68/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 69/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 70/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0041 - val_mae: 0.0506\n",
      "Epoch 71/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 72/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 73/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 74/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 75/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0459 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 76/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0041 - val_mae: 0.0496\n",
      "Epoch 77/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 78/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0492 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 79/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0041 - val_mae: 0.0497\n",
      "Epoch 80/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0040 - mae: 0.0497 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 81/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0044 - val_mae: 0.0532\n",
      "Epoch 82/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 83/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0036 - mae: 0.0466 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 84/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 85/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 86/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0477 - val_loss: 0.0042 - val_mae: 0.0500\n",
      "Epoch 87/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 88/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 89/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 90/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 91/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0041 - val_mae: 0.0506\n",
      "Epoch 92/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 93/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 94/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 95/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0041 - val_mae: 0.0499\n",
      "Epoch 96/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 97/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 98/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 10, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 4s 11ms/step - loss: 0.0730 - mae: 0.1999 - val_loss: 0.0120 - val_mae: 0.0867\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0121 - mae: 0.0864 - val_loss: 0.0103 - val_mae: 0.0803\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0113 - mae: 0.0831 - val_loss: 0.0098 - val_mae: 0.0788\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0109 - mae: 0.0840 - val_loss: 0.0111 - val_mae: 0.0847\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0115 - mae: 0.0846 - val_loss: 0.0102 - val_mae: 0.0803\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0104 - mae: 0.0811 - val_loss: 0.0096 - val_mae: 0.0773\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0105 - mae: 0.0810 - val_loss: 0.0096 - val_mae: 0.0782\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0108 - mae: 0.0813 - val_loss: 0.0111 - val_mae: 0.0847\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0114 - mae: 0.0854 - val_loss: 0.0096 - val_mae: 0.0774\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0116 - mae: 0.0853 - val_loss: 0.0112 - val_mae: 0.0846\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0108 - mae: 0.0819 - val_loss: 0.0113 - val_mae: 0.0858\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0097 - mae: 0.0790 - val_loss: 0.0099 - val_mae: 0.0798\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0096 - mae: 0.0776 - val_loss: 0.0094 - val_mae: 0.0777\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0099 - mae: 0.0778 - val_loss: 0.0099 - val_mae: 0.0788\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0103 - mae: 0.0811 - val_loss: 0.0093 - val_mae: 0.0761\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0104 - mae: 0.0812 - val_loss: 0.0105 - val_mae: 0.0809\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0092 - mae: 0.0743 - val_loss: 0.0089 - val_mae: 0.0752\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0087 - mae: 0.0733 - val_loss: 0.0087 - val_mae: 0.0747\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0093 - mae: 0.0755 - val_loss: 0.0089 - val_mae: 0.0749\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0097 - mae: 0.0770 - val_loss: 0.0100 - val_mae: 0.0787\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0085 - mae: 0.0736 - val_loss: 0.0118 - val_mae: 0.0864\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0092 - mae: 0.0762 - val_loss: 0.0117 - val_mae: 0.0871\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0086 - mae: 0.0738 - val_loss: 0.0091 - val_mae: 0.0753\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0085 - mae: 0.0736 - val_loss: 0.0110 - val_mae: 0.0831\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0085 - mae: 0.0730 - val_loss: 0.0113 - val_mae: 0.0852\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0075 - mae: 0.0683 - val_loss: 0.0142 - val_mae: 0.0960\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0085 - mae: 0.0727 - val_loss: 0.0141 - val_mae: 0.0964\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0075 - mae: 0.0678 - val_loss: 0.0162 - val_mae: 0.1043\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0077 - mae: 0.0700 - val_loss: 0.0177 - val_mae: 0.1093\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0071 - mae: 0.0661 - val_loss: 0.0162 - val_mae: 0.1048\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0067 - mae: 0.0640 - val_loss: 0.0137 - val_mae: 0.0956\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0068 - mae: 0.0645 - val_loss: 0.0159 - val_mae: 0.1034\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0067 - mae: 0.0646 - val_loss: 0.0160 - val_mae: 0.1047\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0067 - mae: 0.0641 - val_loss: 0.0175 - val_mae: 0.1101\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0070 - mae: 0.0663 - val_loss: 0.0180 - val_mae: 0.1118\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0077 - mae: 0.0700 - val_loss: 0.0163 - val_mae: 0.1061\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0064 - mae: 0.0640 - val_loss: 0.0256 - val_mae: 0.1356\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0070 - mae: 0.0672 - val_loss: 0.0155 - val_mae: 0.1036\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 10, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 3s 10ms/step - loss: 0.2994 - mae: 0.4533 - val_loss: 0.0178 - val_mae: 0.1069\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0161 - mae: 0.1007 - val_loss: 0.0141 - val_mae: 0.0941\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0149 - mae: 0.0949 - val_loss: 0.0134 - val_mae: 0.0923\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0150 - mae: 0.0979 - val_loss: 0.0121 - val_mae: 0.0875\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0137 - mae: 0.0926 - val_loss: 0.0112 - val_mae: 0.0842\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0146 - mae: 0.0963 - val_loss: 0.0116 - val_mae: 0.0853\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0128 - mae: 0.0897 - val_loss: 0.0129 - val_mae: 0.0912\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0142 - mae: 0.0944 - val_loss: 0.0136 - val_mae: 0.0939\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0121 - mae: 0.0872 - val_loss: 0.0134 - val_mae: 0.0933\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0121 - mae: 0.0861 - val_loss: 0.0122 - val_mae: 0.0879\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0114 - mae: 0.0840 - val_loss: 0.0134 - val_mae: 0.0935\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0123 - mae: 0.0871 - val_loss: 0.0153 - val_mae: 0.0994\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0120 - mae: 0.0852 - val_loss: 0.0181 - val_mae: 0.1083\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0107 - mae: 0.0806 - val_loss: 0.0166 - val_mae: 0.1033\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0112 - mae: 0.0828 - val_loss: 0.0260 - val_mae: 0.1337\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0092 - mae: 0.0764 - val_loss: 0.0288 - val_mae: 0.1406\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0096 - mae: 0.0782 - val_loss: 0.0473 - val_mae: 0.1844\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0102 - mae: 0.0789 - val_loss: 0.0348 - val_mae: 0.1550\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0085 - mae: 0.0718 - val_loss: 0.0644 - val_mae: 0.2178\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0081 - mae: 0.0716 - val_loss: 0.0708 - val_mae: 0.2297\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0074 - mae: 0.0681 - val_loss: 0.0719 - val_mae: 0.2303\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0078 - mae: 0.0694 - val_loss: 0.0704 - val_mae: 0.2294\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0080 - mae: 0.0707 - val_loss: 0.0735 - val_mae: 0.2326\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0081 - mae: 0.0722 - val_loss: 0.0825 - val_mae: 0.2515\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0071 - mae: 0.0670 - val_loss: 0.0830 - val_mae: 0.2499\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 20, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 4s 10ms/step - loss: 0.0357 - mae: 0.1394 - val_loss: 0.0088 - val_mae: 0.0732\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0069 - mae: 0.0655 - val_loss: 0.0078 - val_mae: 0.0701\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0067 - mae: 0.0651 - val_loss: 0.0075 - val_mae: 0.0686\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0060 - mae: 0.0607 - val_loss: 0.0075 - val_mae: 0.0685\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0058 - mae: 0.0604 - val_loss: 0.0065 - val_mae: 0.0639\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0057 - mae: 0.0594 - val_loss: 0.0060 - val_mae: 0.0615\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0052 - mae: 0.0571 - val_loss: 0.0058 - val_mae: 0.0602\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0052 - mae: 0.0573 - val_loss: 0.0054 - val_mae: 0.0579\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0048 - mae: 0.0547 - val_loss: 0.0050 - val_mae: 0.0562\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0041 - mae: 0.0505 - val_loss: 0.0048 - val_mae: 0.0548\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0049 - val_mae: 0.0556\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0046 - val_mae: 0.0535\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0042 - mae: 0.0514 - val_loss: 0.0048 - val_mae: 0.0552\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0043 - val_mae: 0.0507\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0043 - val_mae: 0.0505\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0041 - val_mae: 0.0501\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0041 - val_mae: 0.0498\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0042 - val_mae: 0.0507\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0470 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0042 - val_mae: 0.0512\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0041 - mae: 0.0499 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0041 - val_mae: 0.0490\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0033 - mae: 0.0457 - val_loss: 0.0041 - val_mae: 0.0490\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0040 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0041 - val_mae: 0.0510\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0456 - val_loss: 0.0046 - val_mae: 0.0544\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0042 - val_mae: 0.0496\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0034 - mae: 0.0458 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0043 - val_mae: 0.0503\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0465 - val_loss: 0.0040 - val_mae: 0.0497\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0498 - val_loss: 0.0041 - val_mae: 0.0508\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0039 - val_mae: 0.0492\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0033 - mae: 0.0451 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0498 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 54/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0040 - val_mae: 0.0505\n",
      "Epoch 55/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 56/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0040 - val_mae: 0.0498\n",
      "Epoch 57/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0034 - mae: 0.0457 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 58/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 59/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0034 - mae: 0.0457 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 60/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 61/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0034 - mae: 0.0463 - val_loss: 0.0044 - val_mae: 0.0537\n",
      "Epoch 62/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0042 - mae: 0.0507 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 63/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 64/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 65/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0458 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 66/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0034 - mae: 0.0458 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 67/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 68/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0041 - mae: 0.0498 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 69/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0039 - val_mae: 0.0496\n",
      "Epoch 70/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 71/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 72/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 73/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0038 - val_mae: 0.0489\n",
      "Epoch 74/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0041 - val_mae: 0.0512\n",
      "Epoch 75/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0478 - val_loss: 0.0041 - val_mae: 0.0506\n",
      "Epoch 76/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 77/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0038 - val_mae: 0.0480\n",
      "Epoch 78/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 79/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0039 - val_mae: 0.0480\n",
      "Epoch 80/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0459 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 81/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 82/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0038 - mae: 0.0493 - val_loss: 0.0041 - val_mae: 0.0515\n",
      "Epoch 83/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 84/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0034 - mae: 0.0457 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 85/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 86/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0496\n",
      "Epoch 87/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 88/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 89/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0033 - mae: 0.0456 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 90/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0485\n",
      "Epoch 91/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 92/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 93/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0038 - val_mae: 0.0477\n",
      "Epoch 94/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0034 - mae: 0.0463 - val_loss: 0.0038 - val_mae: 0.0485\n",
      "Epoch 95/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0038 - val_mae: 0.0482\n",
      "Epoch 96/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0471 - val_loss: 0.0038 - val_mae: 0.0479\n",
      "Epoch 97/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0038 - val_mae: 0.0485\n",
      "Epoch 98/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 99/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 100/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 101/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 102/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0038 - val_mae: 0.0483\n",
      "Epoch 103/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0492\n",
      "Epoch 104/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0473 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 105/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0479 - val_loss: 0.0038 - val_mae: 0.0484\n",
      "Epoch 106/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0034 - mae: 0.0457 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 107/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0462 - val_loss: 0.0038 - val_mae: 0.0479\n",
      "Epoch 108/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0038 - val_mae: 0.0480\n",
      "Epoch 109/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0038 - val_mae: 0.0478\n",
      "Epoch 110/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 111/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 112/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0038 - val_mae: 0.0482\n",
      "Epoch 113/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0038 - val_mae: 0.0482\n",
      "Epoch 114/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 115/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 116/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0480\n",
      "Epoch 117/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0488\n",
      "Epoch 118/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0466 - val_loss: 0.0038 - val_mae: 0.0486\n",
      "Epoch 119/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0034 - mae: 0.0462 - val_loss: 0.0039 - val_mae: 0.0493\n",
      "Epoch 120/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 121/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0478\n",
      "Epoch 122/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 123/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 124/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0039 - val_mae: 0.0498\n",
      "Epoch 125/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0039 - val_mae: 0.0479\n",
      "Epoch 126/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 127/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0497 - val_loss: 0.0039 - val_mae: 0.0480\n",
      "Epoch 128/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0497\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 20, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 3s 11ms/step - loss: 0.0819 - mae: 0.2045 - val_loss: 0.0117 - val_mae: 0.0855\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0119 - mae: 0.0866 - val_loss: 0.0114 - val_mae: 0.0854\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0110 - mae: 0.0849 - val_loss: 0.0105 - val_mae: 0.0814\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0107 - mae: 0.0818 - val_loss: 0.0097 - val_mae: 0.0786\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0104 - mae: 0.0806 - val_loss: 0.0105 - val_mae: 0.0812\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0109 - mae: 0.0829 - val_loss: 0.0097 - val_mae: 0.0781\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0107 - mae: 0.0835 - val_loss: 0.0092 - val_mae: 0.0766\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0103 - mae: 0.0786 - val_loss: 0.0092 - val_mae: 0.0764\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0097 - mae: 0.0781 - val_loss: 0.0097 - val_mae: 0.0778\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0104 - mae: 0.0820 - val_loss: 0.0093 - val_mae: 0.0756\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0096 - mae: 0.0772 - val_loss: 0.0092 - val_mae: 0.0764\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0102 - mae: 0.0810 - val_loss: 0.0091 - val_mae: 0.0749\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0089 - mae: 0.0747 - val_loss: 0.0090 - val_mae: 0.0749\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0095 - mae: 0.0779 - val_loss: 0.0111 - val_mae: 0.0838\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0095 - mae: 0.0768 - val_loss: 0.0102 - val_mae: 0.0799\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0086 - mae: 0.0744 - val_loss: 0.0087 - val_mae: 0.0737\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0086 - mae: 0.0729 - val_loss: 0.0088 - val_mae: 0.0741\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0076 - mae: 0.0703 - val_loss: 0.0111 - val_mae: 0.0850\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0084 - mae: 0.0742 - val_loss: 0.0093 - val_mae: 0.0763\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0078 - mae: 0.0695 - val_loss: 0.0113 - val_mae: 0.0858\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0075 - mae: 0.0691 - val_loss: 0.0112 - val_mae: 0.0838\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0081 - mae: 0.0710 - val_loss: 0.0168 - val_mae: 0.1054\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0073 - mae: 0.0678 - val_loss: 0.0105 - val_mae: 0.0816\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0068 - mae: 0.0652 - val_loss: 0.0123 - val_mae: 0.0891\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0063 - mae: 0.0615 - val_loss: 0.0145 - val_mae: 0.0987\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0073 - mae: 0.0684 - val_loss: 0.0121 - val_mae: 0.0876\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0064 - mae: 0.0635 - val_loss: 0.0143 - val_mae: 0.0974\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0074 - mae: 0.0683 - val_loss: 0.0218 - val_mae: 0.1237\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0077 - mae: 0.0685 - val_loss: 0.0171 - val_mae: 0.1075\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0064 - mae: 0.0635 - val_loss: 0.0185 - val_mae: 0.1125\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0069 - mae: 0.0658 - val_loss: 0.0215 - val_mae: 0.1218\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0072 - mae: 0.0674 - val_loss: 0.0134 - val_mae: 0.0951\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0064 - mae: 0.0633 - val_loss: 0.0159 - val_mae: 0.1043\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0067 - mae: 0.0648 - val_loss: 0.0134 - val_mae: 0.0950\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0073 - mae: 0.0679 - val_loss: 0.0142 - val_mae: 0.0983\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0062 - mae: 0.0625 - val_loss: 0.0121 - val_mae: 0.0901\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 20, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 4s 11ms/step - loss: 0.1120 - mae: 0.2496 - val_loss: 0.0130 - val_mae: 0.0898\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0154 - mae: 0.0981 - val_loss: 0.0120 - val_mae: 0.0864\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0156 - mae: 0.0997 - val_loss: 0.0121 - val_mae: 0.0873\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0142 - mae: 0.0955 - val_loss: 0.0113 - val_mae: 0.0837\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0143 - mae: 0.0949 - val_loss: 0.0142 - val_mae: 0.0962\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0150 - mae: 0.0980 - val_loss: 0.0123 - val_mae: 0.0879\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0144 - mae: 0.0941 - val_loss: 0.0119 - val_mae: 0.0860\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0131 - mae: 0.0904 - val_loss: 0.0111 - val_mae: 0.0831\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0146 - mae: 0.0963 - val_loss: 0.0126 - val_mae: 0.0894\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0129 - mae: 0.0889 - val_loss: 0.0131 - val_mae: 0.0909\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0116 - mae: 0.0854 - val_loss: 0.0102 - val_mae: 0.0796\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0124 - mae: 0.0876 - val_loss: 0.0128 - val_mae: 0.0900\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0115 - mae: 0.0844 - val_loss: 0.0138 - val_mae: 0.0934\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0116 - mae: 0.0846 - val_loss: 0.0142 - val_mae: 0.0954\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0115 - mae: 0.0849 - val_loss: 0.0137 - val_mae: 0.0937\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0123 - mae: 0.0870 - val_loss: 0.0132 - val_mae: 0.0912\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0113 - mae: 0.0846 - val_loss: 0.0200 - val_mae: 0.1147\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0099 - mae: 0.0795 - val_loss: 0.0258 - val_mae: 0.1328\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0092 - mae: 0.0760 - val_loss: 0.0304 - val_mae: 0.1426\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0094 - mae: 0.0776 - val_loss: 0.0240 - val_mae: 0.1253\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0097 - mae: 0.0774 - val_loss: 0.0361 - val_mae: 0.1587\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0080 - mae: 0.0706 - val_loss: 0.0351 - val_mae: 0.1575\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0093 - mae: 0.0753 - val_loss: 0.0299 - val_mae: 0.1422\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0083 - mae: 0.0728 - val_loss: 0.0404 - val_mae: 0.1684\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0081 - mae: 0.0715 - val_loss: 0.0384 - val_mae: 0.1632\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0077 - mae: 0.0690 - val_loss: 0.0643 - val_mae: 0.2179\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0073 - mae: 0.0659 - val_loss: 0.0493 - val_mae: 0.1905\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0075 - mae: 0.0680 - val_loss: 0.0403 - val_mae: 0.1689\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0074 - mae: 0.0683 - val_loss: 0.0409 - val_mae: 0.1700\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0074 - mae: 0.0686 - val_loss: 0.0518 - val_mae: 0.1963\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0070 - mae: 0.0656 - val_loss: 0.0502 - val_mae: 0.1911\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 40, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 3s 11ms/step - loss: 0.0221 - mae: 0.1082 - val_loss: 0.0096 - val_mae: 0.0783\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0072 - mae: 0.0681 - val_loss: 0.0087 - val_mae: 0.0751\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0072 - mae: 0.0681 - val_loss: 0.0075 - val_mae: 0.0690\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0062 - mae: 0.0623 - val_loss: 0.0071 - val_mae: 0.0671\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0056 - mae: 0.0593 - val_loss: 0.0067 - val_mae: 0.0652\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0050 - mae: 0.0563 - val_loss: 0.0069 - val_mae: 0.0656\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0050 - mae: 0.0559 - val_loss: 0.0058 - val_mae: 0.0604\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0049 - mae: 0.0560 - val_loss: 0.0056 - val_mae: 0.0594\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0045 - mae: 0.0531 - val_loss: 0.0052 - val_mae: 0.0574\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0044 - mae: 0.0527 - val_loss: 0.0053 - val_mae: 0.0569\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0048 - val_mae: 0.0551\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0045 - val_mae: 0.0528\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0039 - mae: 0.0499 - val_loss: 0.0046 - val_mae: 0.0523\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0043 - val_mae: 0.0509\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0043 - val_mae: 0.0510\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0041 - val_mae: 0.0500\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0042 - val_mae: 0.0501\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0470 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0488\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0040 - val_mae: 0.0500\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0492 - val_loss: 0.0042 - val_mae: 0.0516\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0041 - val_mae: 0.0498\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0034 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0502\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0492 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0466 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0044 - val_mae: 0.0512\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0043 - val_mae: 0.0505\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0035 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0471 - val_loss: 0.0040 - val_mae: 0.0498\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0038 - val_mae: 0.0482\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0496\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0041 - val_mae: 0.0493\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 54/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 55/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0480\n",
      "Epoch 56/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0463 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 57/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0479\n",
      "Epoch 58/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 59/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 60/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 61/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 62/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0041 - val_mae: 0.0507\n",
      "Epoch 63/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 64/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0488\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 40, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 3s 11ms/step - loss: 0.0327 - mae: 0.1348 - val_loss: 0.0114 - val_mae: 0.0847\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0120 - mae: 0.0882 - val_loss: 0.0107 - val_mae: 0.0829\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0118 - mae: 0.0870 - val_loss: 0.0115 - val_mae: 0.0873\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0112 - mae: 0.0837 - val_loss: 0.0106 - val_mae: 0.0813\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0114 - mae: 0.0840 - val_loss: 0.0091 - val_mae: 0.0750\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0104 - mae: 0.0802 - val_loss: 0.0094 - val_mae: 0.0776\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0109 - mae: 0.0840 - val_loss: 0.0098 - val_mae: 0.0787\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0100 - mae: 0.0796 - val_loss: 0.0089 - val_mae: 0.0741\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0109 - mae: 0.0818 - val_loss: 0.0095 - val_mae: 0.0766\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0105 - mae: 0.0820 - val_loss: 0.0118 - val_mae: 0.0880\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0102 - mae: 0.0803 - val_loss: 0.0090 - val_mae: 0.0761\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0107 - mae: 0.0822 - val_loss: 0.0107 - val_mae: 0.0846\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0097 - mae: 0.0789 - val_loss: 0.0091 - val_mae: 0.0767\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0102 - mae: 0.0805 - val_loss: 0.0139 - val_mae: 0.0932\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0104 - mae: 0.0815 - val_loss: 0.0087 - val_mae: 0.0739\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0105 - mae: 0.0821 - val_loss: 0.0097 - val_mae: 0.0777\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0097 - mae: 0.0774 - val_loss: 0.0094 - val_mae: 0.0763\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0093 - mae: 0.0766 - val_loss: 0.0087 - val_mae: 0.0738\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0084 - mae: 0.0723 - val_loss: 0.0087 - val_mae: 0.0736\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0087 - mae: 0.0727 - val_loss: 0.0079 - val_mae: 0.0708\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 8ms/step - loss: 0.0081 - mae: 0.0715 - val_loss: 0.0109 - val_mae: 0.0835\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0073 - mae: 0.0676 - val_loss: 0.0099 - val_mae: 0.0789\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0073 - mae: 0.0670 - val_loss: 0.0137 - val_mae: 0.0955\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0071 - mae: 0.0660 - val_loss: 0.0157 - val_mae: 0.1021\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0074 - mae: 0.0676 - val_loss: 0.0131 - val_mae: 0.0914\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0062 - mae: 0.0619 - val_loss: 0.0143 - val_mae: 0.0978\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0073 - mae: 0.0676 - val_loss: 0.0144 - val_mae: 0.0969\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0072 - mae: 0.0676 - val_loss: 0.0177 - val_mae: 0.1103\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0065 - mae: 0.0639 - val_loss: 0.0128 - val_mae: 0.0919\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0068 - mae: 0.0655 - val_loss: 0.0143 - val_mae: 0.0990\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0064 - mae: 0.0628 - val_loss: 0.0123 - val_mae: 0.0903\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0059 - mae: 0.0605 - val_loss: 0.0189 - val_mae: 0.1148\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0057 - mae: 0.0594 - val_loss: 0.0133 - val_mae: 0.0951\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0060 - mae: 0.0609 - val_loss: 0.0117 - val_mae: 0.0884\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0059 - mae: 0.0609 - val_loss: 0.0141 - val_mae: 0.0984\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0060 - mae: 0.0608 - val_loss: 0.0153 - val_mae: 0.1029\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0056 - mae: 0.0598 - val_loss: 0.0167 - val_mae: 0.1082\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0055 - mae: 0.0574 - val_loss: 0.0181 - val_mae: 0.1139\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0055 - mae: 0.0585 - val_loss: 0.0203 - val_mae: 0.1209\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0053 - mae: 0.0584 - val_loss: 0.0149 - val_mae: 0.1025\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 40, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 4s 11ms/step - loss: 0.0392 - mae: 0.1532 - val_loss: 0.0131 - val_mae: 0.0907\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0139 - mae: 0.0928 - val_loss: 0.0146 - val_mae: 0.0968\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0163 - mae: 0.1016 - val_loss: 0.0116 - val_mae: 0.0859\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0138 - mae: 0.0926 - val_loss: 0.0111 - val_mae: 0.0833\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0135 - mae: 0.0921 - val_loss: 0.0126 - val_mae: 0.0892\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0142 - mae: 0.0933 - val_loss: 0.0125 - val_mae: 0.0885\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0149 - mae: 0.0955 - val_loss: 0.0122 - val_mae: 0.0879\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0124 - mae: 0.0885 - val_loss: 0.0124 - val_mae: 0.0882\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0128 - mae: 0.0899 - val_loss: 0.0118 - val_mae: 0.0861\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0120 - mae: 0.0861 - val_loss: 0.0265 - val_mae: 0.1337\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0131 - mae: 0.0907 - val_loss: 0.0209 - val_mae: 0.1163\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0105 - mae: 0.0811 - val_loss: 0.0304 - val_mae: 0.1433\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0090 - mae: 0.0744 - val_loss: 0.0612 - val_mae: 0.2100\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0085 - mae: 0.0744 - val_loss: 0.0277 - val_mae: 0.1360\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0092 - mae: 0.0763 - val_loss: 0.0344 - val_mae: 0.1550\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0092 - mae: 0.0763 - val_loss: 0.0449 - val_mae: 0.1762\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0079 - mae: 0.0703 - val_loss: 0.0430 - val_mae: 0.1733\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0104 - mae: 0.0794 - val_loss: 0.0602 - val_mae: 0.2139\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0080 - mae: 0.0716 - val_loss: 0.0650 - val_mae: 0.2228\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0075 - mae: 0.0687 - val_loss: 0.0424 - val_mae: 0.1749\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0090 - mae: 0.0748 - val_loss: 0.0522 - val_mae: 0.1955\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0070 - mae: 0.0659 - val_loss: 0.0482 - val_mae: 0.1886\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0078 - mae: 0.0691 - val_loss: 0.0500 - val_mae: 0.1925\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0075 - mae: 0.0673 - val_loss: 0.0675 - val_mae: 0.2290\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 80, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 3s 12ms/step - loss: 0.0250 - mae: 0.1145 - val_loss: 0.0089 - val_mae: 0.0754\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0077 - mae: 0.0686 - val_loss: 0.0079 - val_mae: 0.0711\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0061 - mae: 0.0620 - val_loss: 0.0075 - val_mae: 0.0694\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0059 - mae: 0.0614 - val_loss: 0.0069 - val_mae: 0.0658\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0056 - mae: 0.0595 - val_loss: 0.0062 - val_mae: 0.0622\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0047 - mae: 0.0535 - val_loss: 0.0057 - val_mae: 0.0606\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0045 - mae: 0.0538 - val_loss: 0.0051 - val_mae: 0.0569\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0043 - mae: 0.0519 - val_loss: 0.0048 - val_mae: 0.0544\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0047 - mae: 0.0533 - val_loss: 0.0049 - val_mae: 0.0546\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0042 - mae: 0.0512 - val_loss: 0.0046 - val_mae: 0.0530\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0049 - val_mae: 0.0541\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0045 - val_mae: 0.0515\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0043 - mae: 0.0516 - val_loss: 0.0044 - val_mae: 0.0513\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0044 - val_mae: 0.0509\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0045 - val_mae: 0.0531\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0041 - mae: 0.0500 - val_loss: 0.0042 - val_mae: 0.0508\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0047 - val_mae: 0.0530\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0041 - val_mae: 0.0499\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0464 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0034 - mae: 0.0455 - val_loss: 0.0042 - val_mae: 0.0512\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0040 - mae: 0.0494 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0041 - val_mae: 0.0489\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0044 - val_mae: 0.0527\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0043 - val_mae: 0.0504\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0497 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0037 - mae: 0.0471 - val_loss: 0.0042 - val_mae: 0.0501\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0043 - val_mae: 0.0522\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0040 - val_mae: 0.0497\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0491 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 54/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0036 - mae: 0.0465 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 55/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 56/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 57/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 58/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0468 - val_loss: 0.0043 - val_mae: 0.0525\n",
      "Epoch 59/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 80, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 4s 15ms/step - loss: 0.0294 - mae: 0.1241 - val_loss: 0.0114 - val_mae: 0.0841\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0121 - mae: 0.0866 - val_loss: 0.0102 - val_mae: 0.0794\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0107 - mae: 0.0813 - val_loss: 0.0098 - val_mae: 0.0778\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0116 - mae: 0.0857 - val_loss: 0.0110 - val_mae: 0.0828\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0129 - mae: 0.0909 - val_loss: 0.0088 - val_mae: 0.0746\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0119 - mae: 0.0876 - val_loss: 0.0113 - val_mae: 0.0872\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0113 - mae: 0.0840 - val_loss: 0.0098 - val_mae: 0.0776\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0096 - mae: 0.0776 - val_loss: 0.0099 - val_mae: 0.0811\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0103 - mae: 0.0805 - val_loss: 0.0099 - val_mae: 0.0782\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0100 - mae: 0.0784 - val_loss: 0.0092 - val_mae: 0.0750\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0113 - mae: 0.0823 - val_loss: 0.0095 - val_mae: 0.0768\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0102 - mae: 0.0790 - val_loss: 0.0109 - val_mae: 0.0830\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0108 - mae: 0.0826 - val_loss: 0.0087 - val_mae: 0.0736\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0097 - mae: 0.0781 - val_loss: 0.0082 - val_mae: 0.0718\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0096 - mae: 0.0774 - val_loss: 0.0089 - val_mae: 0.0758\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0102 - mae: 0.0799 - val_loss: 0.0092 - val_mae: 0.0768\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0104 - mae: 0.0812 - val_loss: 0.0090 - val_mae: 0.0749\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0092 - mae: 0.0753 - val_loss: 0.0082 - val_mae: 0.0715\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0087 - mae: 0.0727 - val_loss: 0.0099 - val_mae: 0.0790\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0082 - mae: 0.0715 - val_loss: 0.0134 - val_mae: 0.0923\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0077 - mae: 0.0696 - val_loss: 0.0141 - val_mae: 0.0955\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0076 - mae: 0.0687 - val_loss: 0.0115 - val_mae: 0.0864\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0073 - mae: 0.0674 - val_loss: 0.0148 - val_mae: 0.0993\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0067 - mae: 0.0648 - val_loss: 0.0231 - val_mae: 0.1280\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0062 - mae: 0.0627 - val_loss: 0.0157 - val_mae: 0.1044\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0066 - mae: 0.0641 - val_loss: 0.0198 - val_mae: 0.1187\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0062 - mae: 0.0619 - val_loss: 0.0176 - val_mae: 0.1108\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0061 - mae: 0.0618 - val_loss: 0.0158 - val_mae: 0.1048\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0061 - mae: 0.0622 - val_loss: 0.0152 - val_mae: 0.1024\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0060 - mae: 0.0617 - val_loss: 0.0132 - val_mae: 0.0954\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0066 - mae: 0.0632 - val_loss: 0.0169 - val_mae: 0.1094\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0050 - mae: 0.0558 - val_loss: 0.0188 - val_mae: 0.1179\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0057 - mae: 0.0599 - val_loss: 0.0213 - val_mae: 0.1248\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0054 - mae: 0.0576 - val_loss: 0.0160 - val_mae: 0.1064\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0056 - mae: 0.0589 - val_loss: 0.0149 - val_mae: 0.1026\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0055 - mae: 0.0591 - val_loss: 0.0156 - val_mae: 0.1056\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0053 - mae: 0.0568 - val_loss: 0.0227 - val_mae: 0.1291\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0048 - mae: 0.0546 - val_loss: 0.0166 - val_mae: 0.1090\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 80, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 4s 12ms/step - loss: 0.0381 - mae: 0.1532 - val_loss: 0.0146 - val_mae: 0.0955\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0153 - mae: 0.0999 - val_loss: 0.0138 - val_mae: 0.0933\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0156 - mae: 0.0974 - val_loss: 0.0153 - val_mae: 0.1002\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0163 - mae: 0.1007 - val_loss: 0.0153 - val_mae: 0.0984\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0141 - mae: 0.0950 - val_loss: 0.0131 - val_mae: 0.0917\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0127 - mae: 0.0897 - val_loss: 0.0116 - val_mae: 0.0859\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0148 - mae: 0.0953 - val_loss: 0.0116 - val_mae: 0.0857\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0133 - mae: 0.0904 - val_loss: 0.0152 - val_mae: 0.0990\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0135 - mae: 0.0920 - val_loss: 0.0157 - val_mae: 0.1005\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0108 - mae: 0.0817 - val_loss: 0.0174 - val_mae: 0.1059\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0105 - mae: 0.0814 - val_loss: 0.0342 - val_mae: 0.1536\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0110 - mae: 0.0820 - val_loss: 0.0316 - val_mae: 0.1482\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0090 - mae: 0.0756 - val_loss: 0.0503 - val_mae: 0.1900\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0092 - mae: 0.0755 - val_loss: 0.0400 - val_mae: 0.1686\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0081 - mae: 0.0726 - val_loss: 0.0413 - val_mae: 0.1711\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0102 - mae: 0.0788 - val_loss: 0.0386 - val_mae: 0.1666\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0084 - mae: 0.0723 - val_loss: 0.0523 - val_mae: 0.1987\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0085 - mae: 0.0731 - val_loss: 0.0257 - val_mae: 0.1321\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0081 - mae: 0.0712 - val_loss: 0.0488 - val_mae: 0.1901\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0069 - mae: 0.0651 - val_loss: 0.0461 - val_mae: 0.1814\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0074 - mae: 0.0667 - val_loss: 0.0493 - val_mae: 0.1903\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0068 - mae: 0.0641 - val_loss: 0.0523 - val_mae: 0.1980\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0073 - mae: 0.0686 - val_loss: 0.0508 - val_mae: 0.1940\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0072 - mae: 0.0657 - val_loss: 0.0547 - val_mae: 0.2035\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0064 - mae: 0.0621 - val_loss: 0.0464 - val_mae: 0.1856\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0071 - mae: 0.0664 - val_loss: 0.0598 - val_mae: 0.2148\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 160, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 3s 12ms/step - loss: 0.0494 - mae: 0.1397 - val_loss: 0.0093 - val_mae: 0.0765\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0079 - mae: 0.0708 - val_loss: 0.0087 - val_mae: 0.0732\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0072 - mae: 0.0670 - val_loss: 0.0087 - val_mae: 0.0745\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0068 - mae: 0.0653 - val_loss: 0.0074 - val_mae: 0.0682\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0063 - mae: 0.0626 - val_loss: 0.0067 - val_mae: 0.0651\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0053 - mae: 0.0584 - val_loss: 0.0062 - val_mae: 0.0622\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0049 - mae: 0.0553 - val_loss: 0.0058 - val_mae: 0.0606\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0047 - mae: 0.0542 - val_loss: 0.0053 - val_mae: 0.0579\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0041 - mae: 0.0508 - val_loss: 0.0053 - val_mae: 0.0564\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0042 - mae: 0.0512 - val_loss: 0.0046 - val_mae: 0.0540\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0045 - val_mae: 0.0518\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0042 - val_mae: 0.0501\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0041 - val_mae: 0.0506\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0044 - val_mae: 0.0528\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0041 - mae: 0.0501 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0041 - val_mae: 0.0493\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0040 - mae: 0.0505 - val_loss: 0.0045 - val_mae: 0.0542\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0045 - val_mae: 0.0521\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0042 - val_mae: 0.0510\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0481 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0498 - val_loss: 0.0041 - val_mae: 0.0503\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0041 - val_mae: 0.0505\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0042 - val_mae: 0.0510\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0042 - val_mae: 0.0511\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0044 - val_mae: 0.0511\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0465 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0041 - val_mae: 0.0502\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0044 - val_mae: 0.0515\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0039 - val_mae: 0.0493\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0037 - mae: 0.0470 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0041 - val_mae: 0.0496\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0041 - val_mae: 0.0509\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0041 - val_mae: 0.0500\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0040 - val_mae: 0.0498\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0041 - val_mae: 0.0499\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0043 - val_mae: 0.0524\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 160, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 4s 13ms/step - loss: 0.0469 - mae: 0.1421 - val_loss: 0.0110 - val_mae: 0.0821\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0143 - mae: 0.0940 - val_loss: 0.0100 - val_mae: 0.0785\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0132 - mae: 0.0910 - val_loss: 0.0130 - val_mae: 0.0899\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0139 - mae: 0.0936 - val_loss: 0.0095 - val_mae: 0.0772\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0108 - mae: 0.0819 - val_loss: 0.0100 - val_mae: 0.0785\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0127 - mae: 0.0891 - val_loss: 0.0092 - val_mae: 0.0762\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0108 - mae: 0.0815 - val_loss: 0.0095 - val_mae: 0.0768\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0108 - mae: 0.0824 - val_loss: 0.0094 - val_mae: 0.0780\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0110 - mae: 0.0819 - val_loss: 0.0094 - val_mae: 0.0760\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0107 - mae: 0.0816 - val_loss: 0.0105 - val_mae: 0.0814\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0112 - mae: 0.0830 - val_loss: 0.0128 - val_mae: 0.0900\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0096 - mae: 0.0776 - val_loss: 0.0089 - val_mae: 0.0746\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0100 - mae: 0.0797 - val_loss: 0.0090 - val_mae: 0.0744\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0100 - mae: 0.0794 - val_loss: 0.0085 - val_mae: 0.0735\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0105 - mae: 0.0797 - val_loss: 0.0088 - val_mae: 0.0740\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0109 - mae: 0.0832 - val_loss: 0.0086 - val_mae: 0.0733\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0092 - mae: 0.0746 - val_loss: 0.0091 - val_mae: 0.0748\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0094 - mae: 0.0774 - val_loss: 0.0094 - val_mae: 0.0768\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0094 - mae: 0.0764 - val_loss: 0.0122 - val_mae: 0.0882\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0083 - mae: 0.0712 - val_loss: 0.0086 - val_mae: 0.0732\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0092 - mae: 0.0754 - val_loss: 0.0142 - val_mae: 0.0964\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0072 - mae: 0.0670 - val_loss: 0.0142 - val_mae: 0.0968\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0073 - mae: 0.0667 - val_loss: 0.0131 - val_mae: 0.0939\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0063 - mae: 0.0644 - val_loss: 0.0122 - val_mae: 0.0897\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0063 - mae: 0.0631 - val_loss: 0.0190 - val_mae: 0.1163\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0058 - mae: 0.0597 - val_loss: 0.0153 - val_mae: 0.1032\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0053 - mae: 0.0581 - val_loss: 0.0150 - val_mae: 0.1023\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0063 - mae: 0.0622 - val_loss: 0.0172 - val_mae: 0.1113\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0055 - mae: 0.0592 - val_loss: 0.0152 - val_mae: 0.1037\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0053 - mae: 0.0575 - val_loss: 0.0195 - val_mae: 0.1191\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0055 - mae: 0.0574 - val_loss: 0.0188 - val_mae: 0.1174\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0052 - mae: 0.0571 - val_loss: 0.0303 - val_mae: 0.1530\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0055 - mae: 0.0584 - val_loss: 0.0176 - val_mae: 0.1129\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0054 - mae: 0.0588 - val_loss: 0.0211 - val_mae: 0.1239\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 1, 'layers_type': 'LSTM', 'units': 160, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 4s 12ms/step - loss: 0.0345 - mae: 0.1363 - val_loss: 0.0136 - val_mae: 0.0926\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0165 - mae: 0.1018 - val_loss: 0.0145 - val_mae: 0.0959\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0133 - mae: 0.0912 - val_loss: 0.0152 - val_mae: 0.0981\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0164 - mae: 0.1010 - val_loss: 0.0114 - val_mae: 0.0841\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0137 - mae: 0.0938 - val_loss: 0.0147 - val_mae: 0.0964\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0153 - mae: 0.0977 - val_loss: 0.0138 - val_mae: 0.0932\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0155 - mae: 0.0992 - val_loss: 0.0151 - val_mae: 0.0978\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0144 - mae: 0.0952 - val_loss: 0.0125 - val_mae: 0.0897\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0147 - mae: 0.0967 - val_loss: 0.0141 - val_mae: 0.0946\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0137 - mae: 0.0913 - val_loss: 0.0113 - val_mae: 0.0844\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0123 - mae: 0.0865 - val_loss: 0.0205 - val_mae: 0.1168\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0106 - mae: 0.0819 - val_loss: 0.0185 - val_mae: 0.1099\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0093 - mae: 0.0769 - val_loss: 0.0420 - val_mae: 0.1729\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0085 - mae: 0.0737 - val_loss: 0.0552 - val_mae: 0.2003\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0082 - mae: 0.0701 - val_loss: 0.0502 - val_mae: 0.1915\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0079 - mae: 0.0708 - val_loss: 0.0555 - val_mae: 0.2032\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0067 - mae: 0.0643 - val_loss: 0.0505 - val_mae: 0.1947\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0070 - mae: 0.0657 - val_loss: 0.0610 - val_mae: 0.2166\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0069 - mae: 0.0653 - val_loss: 0.0644 - val_mae: 0.2230\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0071 - mae: 0.0673 - val_loss: 0.0623 - val_mae: 0.2170\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0067 - mae: 0.0641 - val_loss: 0.0627 - val_mae: 0.2176\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0071 - mae: 0.0648 - val_loss: 0.0823 - val_mae: 0.2602\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0069 - mae: 0.0649 - val_loss: 0.0508 - val_mae: 0.1964\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0069 - mae: 0.0645 - val_loss: 0.0741 - val_mae: 0.2427\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0075 - mae: 0.0675 - val_loss: 0.0689 - val_mae: 0.2321\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 10ms/step - loss: 0.0069 - mae: 0.0659 - val_loss: 0.0710 - val_mae: 0.2336\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0070 - mae: 0.0670 - val_loss: 0.0813 - val_mae: 0.2566\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0072 - mae: 0.0661 - val_loss: 0.0828 - val_mae: 0.2607\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0073 - mae: 0.0667 - val_loss: 0.0744 - val_mae: 0.2405\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 9ms/step - loss: 0.0070 - mae: 0.0644 - val_loss: 0.0623 - val_mae: 0.2199\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 10, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 15ms/step - loss: 0.0696 - mae: 0.2003 - val_loss: 0.0113 - val_mae: 0.0845\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0073 - mae: 0.0673 - val_loss: 0.0077 - val_mae: 0.0694\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0053 - mae: 0.0581 - val_loss: 0.0064 - val_mae: 0.0630\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0048 - mae: 0.0549 - val_loss: 0.0055 - val_mae: 0.0579\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0048 - mae: 0.0544 - val_loss: 0.0049 - val_mae: 0.0536\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0043 - mae: 0.0509 - val_loss: 0.0046 - val_mae: 0.0518\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0044 - val_mae: 0.0507\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0042 - val_mae: 0.0498\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0477 - val_loss: 0.0042 - val_mae: 0.0494\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0042 - val_mae: 0.0495\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0042 - val_mae: 0.0493\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0043 - val_mae: 0.0521\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0042 - mae: 0.0511 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0498\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0042 - val_mae: 0.0512\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0041 - val_mae: 0.0505\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0041 - mae: 0.0496 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0043 - val_mae: 0.0508\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0494 - val_loss: 0.0043 - val_mae: 0.0525\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0036 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0492 - val_loss: 0.0049 - val_mae: 0.0541\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0041 - mae: 0.0502 - val_loss: 0.0045 - val_mae: 0.0518\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0469 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0043 - val_mae: 0.0505\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0041 - val_mae: 0.0509\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0036 - mae: 0.0466 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0043 - val_mae: 0.0503\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0042 - val_mae: 0.0519\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0041 - val_mae: 0.0506\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0048 - val_mae: 0.0539\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0041 - val_mae: 0.0511\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0042 - val_mae: 0.0524\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0043 - val_mae: 0.0523\n",
      "Epoch 54/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0034 - mae: 0.0460 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 55/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0043 - val_mae: 0.0525\n",
      "Epoch 56/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0493 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 57/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 58/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0497\n",
      "Epoch 59/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 60/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0041 - val_mae: 0.0493\n",
      "Epoch 61/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 62/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 63/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0045 - val_mae: 0.0519\n",
      "Epoch 64/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0045 - val_mae: 0.0519\n",
      "Epoch 65/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0044 - val_mae: 0.0533\n",
      "Epoch 66/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0040 - val_mae: 0.0498\n",
      "Epoch 67/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 68/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0042 - val_mae: 0.0517\n",
      "Epoch 69/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0039 - val_mae: 0.0492\n",
      "Epoch 70/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 71/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0046 - val_mae: 0.0549\n",
      "Epoch 72/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0039 - val_mae: 0.0495\n",
      "Epoch 73/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 74/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0476 - val_loss: 0.0043 - val_mae: 0.0517\n",
      "Epoch 75/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 76/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 77/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0034 - mae: 0.0454 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 78/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 79/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 80/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 81/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0042 - mae: 0.0504 - val_loss: 0.0042 - val_mae: 0.0521\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 10, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 6s 15ms/step - loss: 0.0378 - mae: 0.1445 - val_loss: 0.0120 - val_mae: 0.0858\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0151 - mae: 0.0981 - val_loss: 0.0114 - val_mae: 0.0847\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0145 - mae: 0.0937 - val_loss: 0.0123 - val_mae: 0.0884\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0122 - mae: 0.0886 - val_loss: 0.0102 - val_mae: 0.0795\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0119 - mae: 0.0867 - val_loss: 0.0117 - val_mae: 0.0867\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0116 - mae: 0.0854 - val_loss: 0.0100 - val_mae: 0.0787\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0110 - mae: 0.0834 - val_loss: 0.0102 - val_mae: 0.0794\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0106 - mae: 0.0828 - val_loss: 0.0101 - val_mae: 0.0788\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0105 - mae: 0.0808 - val_loss: 0.0106 - val_mae: 0.0814\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0103 - mae: 0.0806 - val_loss: 0.0101 - val_mae: 0.0789\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0094 - mae: 0.0777 - val_loss: 0.0097 - val_mae: 0.0784\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0105 - mae: 0.0818 - val_loss: 0.0096 - val_mae: 0.0772\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0102 - mae: 0.0816 - val_loss: 0.0109 - val_mae: 0.0828\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0093 - mae: 0.0755 - val_loss: 0.0101 - val_mae: 0.0790\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0084 - mae: 0.0730 - val_loss: 0.0141 - val_mae: 0.0956\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0089 - mae: 0.0742 - val_loss: 0.0102 - val_mae: 0.0800\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0101 - mae: 0.0782 - val_loss: 0.0120 - val_mae: 0.0872\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0085 - mae: 0.0727 - val_loss: 0.0177 - val_mae: 0.1080\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0078 - mae: 0.0698 - val_loss: 0.0183 - val_mae: 0.1109\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0091 - mae: 0.0760 - val_loss: 0.0176 - val_mae: 0.1085\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0086 - mae: 0.0731 - val_loss: 0.0142 - val_mae: 0.0954\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0087 - mae: 0.0745 - val_loss: 0.0175 - val_mae: 0.1074\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0082 - mae: 0.0716 - val_loss: 0.0105 - val_mae: 0.0810\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0078 - mae: 0.0688 - val_loss: 0.0175 - val_mae: 0.1076\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0079 - mae: 0.0703 - val_loss: 0.0194 - val_mae: 0.1138\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0076 - mae: 0.0687 - val_loss: 0.0179 - val_mae: 0.1093\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0073 - mae: 0.0678 - val_loss: 0.0209 - val_mae: 0.1199\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0076 - mae: 0.0686 - val_loss: 0.0231 - val_mae: 0.1265\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0075 - mae: 0.0687 - val_loss: 0.0179 - val_mae: 0.1093\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0070 - mae: 0.0669 - val_loss: 0.0206 - val_mae: 0.1173\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0073 - mae: 0.0668 - val_loss: 0.0233 - val_mae: 0.1250\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0075 - mae: 0.0688 - val_loss: 0.0196 - val_mae: 0.1157\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 10, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 15ms/step - loss: 0.1188 - mae: 0.2738 - val_loss: 0.0209 - val_mae: 0.1176\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0266 - mae: 0.1316 - val_loss: 0.0184 - val_mae: 0.1095\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0240 - mae: 0.1233 - val_loss: 0.0163 - val_mae: 0.1021\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0184 - mae: 0.1083 - val_loss: 0.0139 - val_mae: 0.0930\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0184 - mae: 0.1095 - val_loss: 0.0136 - val_mae: 0.0928\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0134 - mae: 0.0926 - val_loss: 0.0165 - val_mae: 0.1029\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0145 - mae: 0.0947 - val_loss: 0.0217 - val_mae: 0.1191\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0129 - mae: 0.0916 - val_loss: 0.0315 - val_mae: 0.1467\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0130 - mae: 0.0896 - val_loss: 0.0298 - val_mae: 0.1412\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0135 - mae: 0.0919 - val_loss: 0.0435 - val_mae: 0.1742\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0127 - mae: 0.0892 - val_loss: 0.0442 - val_mae: 0.1762\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0101 - mae: 0.0798 - val_loss: 0.0476 - val_mae: 0.1833\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0101 - mae: 0.0795 - val_loss: 0.0410 - val_mae: 0.1663\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0106 - mae: 0.0805 - val_loss: 0.0548 - val_mae: 0.1979\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0095 - mae: 0.0772 - val_loss: 0.0504 - val_mae: 0.1879\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0091 - mae: 0.0764 - val_loss: 0.0601 - val_mae: 0.2053\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0094 - mae: 0.0766 - val_loss: 0.0761 - val_mae: 0.2358\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0095 - mae: 0.0761 - val_loss: 0.0628 - val_mae: 0.2123\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0099 - mae: 0.0782 - val_loss: 0.0557 - val_mae: 0.1961\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0097 - mae: 0.0777 - val_loss: 0.0735 - val_mae: 0.2312\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0091 - mae: 0.0766 - val_loss: 0.0598 - val_mae: 0.2030\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0084 - mae: 0.0738 - val_loss: 0.0727 - val_mae: 0.2312\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0090 - mae: 0.0761 - val_loss: 0.0753 - val_mae: 0.2351\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0097 - mae: 0.0782 - val_loss: 0.0741 - val_mae: 0.2335\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0087 - mae: 0.0734 - val_loss: 0.0848 - val_mae: 0.2541\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 20, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 14ms/step - loss: 0.0959 - mae: 0.2120 - val_loss: 0.0091 - val_mae: 0.0740\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0074 - mae: 0.0679 - val_loss: 0.0078 - val_mae: 0.0695\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0057 - mae: 0.0606 - val_loss: 0.0071 - val_mae: 0.0665\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0053 - mae: 0.0579 - val_loss: 0.0059 - val_mae: 0.0601\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0044 - mae: 0.0518 - val_loss: 0.0053 - val_mae: 0.0565\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0046 - mae: 0.0534 - val_loss: 0.0047 - val_mae: 0.0533\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0043 - val_mae: 0.0508\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0042 - val_mae: 0.0512\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0041 - val_mae: 0.0498\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0041 - val_mae: 0.0497\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0477 - val_loss: 0.0044 - val_mae: 0.0529\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0498\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0041 - val_mae: 0.0490\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0042 - val_mae: 0.0491\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0041 - val_mae: 0.0503\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0497 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0043 - val_mae: 0.0522\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0492 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0042 - mae: 0.0501 - val_loss: 0.0041 - val_mae: 0.0488\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0477 - val_loss: 0.0041 - val_mae: 0.0508\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0045 - val_mae: 0.0536\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0495 - val_loss: 0.0041 - val_mae: 0.0504\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0497\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0039 - mae: 0.0483 - val_loss: 0.0041 - val_mae: 0.0501\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0040 - mae: 0.0498 - val_loss: 0.0041 - val_mae: 0.0510\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0042 - mae: 0.0506 - val_loss: 0.0041 - val_mae: 0.0505\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0046 - val_mae: 0.0523\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0042 - val_mae: 0.0499\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0489 - val_loss: 0.0042 - val_mae: 0.0513\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0037 - mae: 0.0468 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0041 - val_mae: 0.0508\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0040 - val_mae: 0.0484\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0494 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 2s 11ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0041 - val_mae: 0.0504\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 20, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 15ms/step - loss: 0.0401 - mae: 0.1546 - val_loss: 0.0116 - val_mae: 0.0848\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0146 - mae: 0.0964 - val_loss: 0.0140 - val_mae: 0.0953\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0120 - mae: 0.0871 - val_loss: 0.0100 - val_mae: 0.0787\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0106 - mae: 0.0823 - val_loss: 0.0113 - val_mae: 0.0846\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0102 - mae: 0.0808 - val_loss: 0.0103 - val_mae: 0.0798\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0104 - mae: 0.0815 - val_loss: 0.0114 - val_mae: 0.0846\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0102 - mae: 0.0807 - val_loss: 0.0139 - val_mae: 0.0946\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0093 - mae: 0.0770 - val_loss: 0.0103 - val_mae: 0.0802\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0093 - mae: 0.0766 - val_loss: 0.0144 - val_mae: 0.0972\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0090 - mae: 0.0746 - val_loss: 0.0149 - val_mae: 0.0988\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0094 - mae: 0.0770 - val_loss: 0.0182 - val_mae: 0.1102\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0086 - mae: 0.0731 - val_loss: 0.0117 - val_mae: 0.0863\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0083 - mae: 0.0722 - val_loss: 0.0129 - val_mae: 0.0912\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0091 - mae: 0.0769 - val_loss: 0.0138 - val_mae: 0.0949\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0085 - mae: 0.0735 - val_loss: 0.0154 - val_mae: 0.1015\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0089 - mae: 0.0740 - val_loss: 0.0183 - val_mae: 0.1112\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0077 - mae: 0.0699 - val_loss: 0.0216 - val_mae: 0.1218\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0067 - mae: 0.0650 - val_loss: 0.0184 - val_mae: 0.1117\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0070 - mae: 0.0662 - val_loss: 0.0205 - val_mae: 0.1191\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0073 - mae: 0.0668 - val_loss: 0.0131 - val_mae: 0.0929\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0065 - mae: 0.0632 - val_loss: 0.0129 - val_mae: 0.0922\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0067 - mae: 0.0645 - val_loss: 0.0189 - val_mae: 0.1143\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0075 - mae: 0.0686 - val_loss: 0.0221 - val_mae: 0.1234\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 20, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 6s 15ms/step - loss: 0.0350 - mae: 0.1505 - val_loss: 0.0155 - val_mae: 0.0995\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0212 - mae: 0.1157 - val_loss: 0.0164 - val_mae: 0.1025\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0156 - mae: 0.0994 - val_loss: 0.0237 - val_mae: 0.1257\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0147 - mae: 0.0962 - val_loss: 0.0297 - val_mae: 0.1407\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0137 - mae: 0.0915 - val_loss: 0.0212 - val_mae: 0.1160\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0128 - mae: 0.0895 - val_loss: 0.0326 - val_mae: 0.1489\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0129 - mae: 0.0890 - val_loss: 0.0623 - val_mae: 0.2119\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0117 - mae: 0.0837 - val_loss: 0.0400 - val_mae: 0.1624\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0102 - mae: 0.0804 - val_loss: 0.0423 - val_mae: 0.1707\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0093 - mae: 0.0759 - val_loss: 0.0409 - val_mae: 0.1686\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0096 - mae: 0.0774 - val_loss: 0.0525 - val_mae: 0.1908\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0097 - mae: 0.0792 - val_loss: 0.0534 - val_mae: 0.1938\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0092 - mae: 0.0762 - val_loss: 0.0628 - val_mae: 0.2120\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0090 - mae: 0.0755 - val_loss: 0.0536 - val_mae: 0.1976\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0099 - mae: 0.0792 - val_loss: 0.0651 - val_mae: 0.2161\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0087 - mae: 0.0735 - val_loss: 0.0559 - val_mae: 0.1978\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0081 - mae: 0.0711 - val_loss: 0.0774 - val_mae: 0.2410\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0085 - mae: 0.0729 - val_loss: 0.0573 - val_mae: 0.2011\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0089 - mae: 0.0754 - val_loss: 0.0796 - val_mae: 0.2440\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0084 - mae: 0.0718 - val_loss: 0.0597 - val_mae: 0.2094\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0091 - mae: 0.0757 - val_loss: 0.0528 - val_mae: 0.1959\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 40, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 16ms/step - loss: 0.0277 - mae: 0.1139 - val_loss: 0.0078 - val_mae: 0.0693\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0059 - mae: 0.0607 - val_loss: 0.0070 - val_mae: 0.0666\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0050 - mae: 0.0556 - val_loss: 0.0051 - val_mae: 0.0553\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0045 - mae: 0.0534 - val_loss: 0.0044 - val_mae: 0.0514\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0044 - mae: 0.0513 - val_loss: 0.0042 - val_mae: 0.0497\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0045 - val_mae: 0.0541\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0050 - val_mae: 0.0554\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0043 - mae: 0.0514 - val_loss: 0.0041 - val_mae: 0.0499\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0482 - val_loss: 0.0044 - val_mae: 0.0529\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0048 - val_mae: 0.0559\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0041 - mae: 0.0499 - val_loss: 0.0040 - val_mae: 0.0485\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0041 - mae: 0.0505 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0043 - mae: 0.0514 - val_loss: 0.0040 - val_mae: 0.0484\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0061 - val_mae: 0.0639\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0044 - val_mae: 0.0512\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0043 - val_mae: 0.0510\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0498 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0043 - val_mae: 0.0514\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0042 - mae: 0.0510 - val_loss: 0.0041 - val_mae: 0.0510\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0492 - val_loss: 0.0041 - val_mae: 0.0510\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 19ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0051 - val_mae: 0.0557\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0043 - mae: 0.0508 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0042 - mae: 0.0502 - val_loss: 0.0042 - val_mae: 0.0517\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0041 - val_mae: 0.0497\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0498 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0043 - val_mae: 0.0525\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0041 - val_mae: 0.0509\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0043 - val_mae: 0.0500\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0041 - mae: 0.0505 - val_loss: 0.0046 - val_mae: 0.0537\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0041 - mae: 0.0501 - val_loss: 0.0041 - val_mae: 0.0489\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0040 - val_mae: 0.0484\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0453 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0483\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0493 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0046 - val_mae: 0.0526\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0492\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0040 - val_mae: 0.0485\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0041 - val_mae: 0.0509\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0046 - val_mae: 0.0525\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0044 - val_mae: 0.0510\n",
      "Epoch 54/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0485\n",
      "Epoch 55/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 56/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 57/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 58/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 59/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0041 - val_mae: 0.0497\n",
      "Epoch 60/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 61/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0046 - val_mae: 0.0550\n",
      "Epoch 62/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0047 - val_mae: 0.0528\n",
      "Epoch 63/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0042 - val_mae: 0.0525\n",
      "Epoch 64/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0468 - val_loss: 0.0041 - val_mae: 0.0515\n",
      "Epoch 65/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 66/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 67/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0488\n",
      "Epoch 68/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0042 - val_mae: 0.0514\n",
      "Epoch 69/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 70/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0039 - val_mae: 0.0492\n",
      "Epoch 71/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0497 - val_loss: 0.0043 - val_mae: 0.0502\n",
      "Epoch 72/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0044 - val_mae: 0.0538\n",
      "Epoch 73/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0499 - val_loss: 0.0042 - val_mae: 0.0515\n",
      "Epoch 74/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0042 - val_mae: 0.0497\n",
      "Epoch 75/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0490 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 76/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0042 - val_mae: 0.0521\n",
      "Epoch 77/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0045 - val_mae: 0.0541\n",
      "Epoch 78/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0044 - val_mae: 0.0538\n",
      "Epoch 79/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0040 - mae: 0.0506 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 80/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 81/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 82/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 83/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0040 - val_mae: 0.0504\n",
      "Epoch 84/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0041 - val_mae: 0.0489\n",
      "Epoch 85/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 86/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0479\n",
      "Epoch 87/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 88/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0041 - val_mae: 0.0509\n",
      "Epoch 89/250\n",
      "186/186 [==============================] - 3s 19ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0040 - val_mae: 0.0498\n",
      "Epoch 90/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 91/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0041 - val_mae: 0.0503\n",
      "Epoch 92/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 93/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0039 - val_mae: 0.0493\n",
      "Epoch 94/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0038 - val_mae: 0.0478\n",
      "Epoch 95/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0040 - val_mae: 0.0506\n",
      "Epoch 96/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0480\n",
      "Epoch 97/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0041 - val_mae: 0.0516\n",
      "Epoch 98/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0038 - val_mae: 0.0479\n",
      "Epoch 99/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 100/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 101/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 102/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0034 - mae: 0.0462 - val_loss: 0.0044 - val_mae: 0.0534\n",
      "Epoch 103/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0042 - val_mae: 0.0502\n",
      "Epoch 104/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 105/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0038 - val_mae: 0.0484\n",
      "Epoch 106/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0042 - val_mae: 0.0495\n",
      "Epoch 107/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0039 - val_mae: 0.0480\n",
      "Epoch 108/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0459 - val_loss: 0.0038 - val_mae: 0.0485\n",
      "Epoch 109/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 110/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 111/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0035 - mae: 0.0469 - val_loss: 0.0038 - val_mae: 0.0474\n",
      "Epoch 112/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0045 - val_mae: 0.0540\n",
      "Epoch 113/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0037 - val_mae: 0.0473\n",
      "Epoch 114/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0038 - val_mae: 0.0488\n",
      "Epoch 115/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0479\n",
      "Epoch 116/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 117/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0492\n",
      "Epoch 118/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0472 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 119/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0034 - mae: 0.0465 - val_loss: 0.0038 - val_mae: 0.0485\n",
      "Epoch 120/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 121/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 122/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0035 - mae: 0.0469 - val_loss: 0.0040 - val_mae: 0.0482\n",
      "Epoch 123/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0035 - mae: 0.0464 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 124/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0036 - mae: 0.0485 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 125/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0038 - val_mae: 0.0474\n",
      "Epoch 126/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 127/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 128/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0038 - val_mae: 0.0485\n",
      "Epoch 129/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0495\n",
      "Epoch 130/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0041 - val_mae: 0.0517\n",
      "Epoch 131/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0034 - mae: 0.0460 - val_loss: 0.0039 - val_mae: 0.0488\n",
      "Epoch 132/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0478\n",
      "Epoch 133/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 40, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 7s 16ms/step - loss: 0.0403 - mae: 0.1434 - val_loss: 0.0110 - val_mae: 0.0822\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0125 - mae: 0.0883 - val_loss: 0.0103 - val_mae: 0.0805\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0112 - mae: 0.0848 - val_loss: 0.0199 - val_mae: 0.1153\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0112 - mae: 0.0836 - val_loss: 0.0093 - val_mae: 0.0757\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0103 - mae: 0.0795 - val_loss: 0.0130 - val_mae: 0.0919\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0094 - mae: 0.0755 - val_loss: 0.0148 - val_mae: 0.0977\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0114 - mae: 0.0837 - val_loss: 0.0105 - val_mae: 0.0811\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0079 - mae: 0.0708 - val_loss: 0.0122 - val_mae: 0.0882\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0074 - mae: 0.0685 - val_loss: 0.0156 - val_mae: 0.1024\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0062 - mae: 0.0620 - val_loss: 0.0177 - val_mae: 0.1096\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0068 - mae: 0.0644 - val_loss: 0.0182 - val_mae: 0.1111\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0066 - mae: 0.0633 - val_loss: 0.0214 - val_mae: 0.1220\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0068 - mae: 0.0649 - val_loss: 0.0220 - val_mae: 0.1239\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0066 - mae: 0.0639 - val_loss: 0.0296 - val_mae: 0.1486\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0066 - mae: 0.0640 - val_loss: 0.0197 - val_mae: 0.1178\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0058 - mae: 0.0599 - val_loss: 0.0185 - val_mae: 0.1144\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0062 - mae: 0.0620 - val_loss: 0.0290 - val_mae: 0.1431\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0067 - mae: 0.0650 - val_loss: 0.0209 - val_mae: 0.1219\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0055 - mae: 0.0590 - val_loss: 0.0237 - val_mae: 0.1314\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0060 - mae: 0.0618 - val_loss: 0.0195 - val_mae: 0.1182\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0056 - mae: 0.0576 - val_loss: 0.0225 - val_mae: 0.1277\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0052 - mae: 0.0558 - val_loss: 0.0222 - val_mae: 0.1297\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0059 - mae: 0.0606 - val_loss: 0.0252 - val_mae: 0.1369\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0060 - mae: 0.0613 - val_loss: 0.0176 - val_mae: 0.1132\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 40, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 15ms/step - loss: 0.0489 - mae: 0.1684 - val_loss: 0.0164 - val_mae: 0.1016\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0199 - mae: 0.1116 - val_loss: 0.0135 - val_mae: 0.0923\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0147 - mae: 0.0950 - val_loss: 0.0185 - val_mae: 0.1091\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0133 - mae: 0.0910 - val_loss: 0.0242 - val_mae: 0.1247\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0110 - mae: 0.0814 - val_loss: 0.0370 - val_mae: 0.1578\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0114 - mae: 0.0856 - val_loss: 0.0378 - val_mae: 0.1603\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0100 - mae: 0.0784 - val_loss: 0.0626 - val_mae: 0.2109\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0096 - mae: 0.0785 - val_loss: 0.0465 - val_mae: 0.1771\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0093 - mae: 0.0771 - val_loss: 0.0791 - val_mae: 0.2409\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0098 - mae: 0.0785 - val_loss: 0.0545 - val_mae: 0.1975\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0084 - mae: 0.0720 - val_loss: 0.0644 - val_mae: 0.2171\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0091 - mae: 0.0768 - val_loss: 0.0687 - val_mae: 0.2269\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0077 - mae: 0.0695 - val_loss: 0.0722 - val_mae: 0.2329\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0082 - mae: 0.0707 - val_loss: 0.0937 - val_mae: 0.2652\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0086 - mae: 0.0728 - val_loss: 0.0848 - val_mae: 0.2488\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0083 - mae: 0.0722 - val_loss: 0.0692 - val_mae: 0.2293\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0087 - mae: 0.0730 - val_loss: 0.0614 - val_mae: 0.2113\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0089 - mae: 0.0742 - val_loss: 0.0736 - val_mae: 0.2336\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0084 - mae: 0.0712 - val_loss: 0.0776 - val_mae: 0.2479\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0083 - mae: 0.0726 - val_loss: 0.0562 - val_mae: 0.2021\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0084 - mae: 0.0722 - val_loss: 0.0571 - val_mae: 0.2040\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0087 - mae: 0.0731 - val_loss: 0.0674 - val_mae: 0.2233\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 80, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 6s 15ms/step - loss: 0.0130 - mae: 0.0890 - val_loss: 0.0068 - val_mae: 0.0650\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0045 - mae: 0.0540 - val_loss: 0.0047 - val_mae: 0.0521\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0041 - mae: 0.0511 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0047 - mae: 0.0539 - val_loss: 0.0051 - val_mae: 0.0559\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0043 - val_mae: 0.0497\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0043 - mae: 0.0509 - val_loss: 0.0043 - val_mae: 0.0504\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0041 - val_mae: 0.0500\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0042 - mae: 0.0502 - val_loss: 0.0039 - val_mae: 0.0478\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0037 - mae: 0.0487 - val_loss: 0.0041 - val_mae: 0.0487\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0043 - mae: 0.0509 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0043 - val_mae: 0.0505\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0492 - val_loss: 0.0045 - val_mae: 0.0519\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0041 - val_mae: 0.0489\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0042 - mae: 0.0513 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0484\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0043 - mae: 0.0514 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0040 - val_mae: 0.0485\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0044 - val_mae: 0.0517\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0062 - val_mae: 0.0624\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0505 - val_loss: 0.0042 - val_mae: 0.0494\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0041 - mae: 0.0508 - val_loss: 0.0044 - val_mae: 0.0509\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0043 - val_mae: 0.0523\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0041 - mae: 0.0501 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 80, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 16ms/step - loss: 0.0381 - mae: 0.1444 - val_loss: 0.0114 - val_mae: 0.0843\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0125 - mae: 0.0865 - val_loss: 0.0121 - val_mae: 0.0869\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0119 - mae: 0.0861 - val_loss: 0.0104 - val_mae: 0.0805\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0115 - mae: 0.0834 - val_loss: 0.0134 - val_mae: 0.0926\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0087 - mae: 0.0745 - val_loss: 0.0118 - val_mae: 0.0864\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0082 - mae: 0.0719 - val_loss: 0.0329 - val_mae: 0.1509\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0087 - mae: 0.0733 - val_loss: 0.0154 - val_mae: 0.1018\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0067 - mae: 0.0645 - val_loss: 0.0180 - val_mae: 0.1112\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0066 - mae: 0.0649 - val_loss: 0.0204 - val_mae: 0.1192\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0071 - mae: 0.0652 - val_loss: 0.0211 - val_mae: 0.1210\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0066 - mae: 0.0654 - val_loss: 0.0195 - val_mae: 0.1167\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0060 - mae: 0.0610 - val_loss: 0.0234 - val_mae: 0.1308\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0060 - mae: 0.0608 - val_loss: 0.0233 - val_mae: 0.1291\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0057 - mae: 0.0581 - val_loss: 0.0188 - val_mae: 0.1154\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0058 - mae: 0.0597 - val_loss: 0.0181 - val_mae: 0.1141\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0059 - mae: 0.0594 - val_loss: 0.0213 - val_mae: 0.1245\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0061 - mae: 0.0605 - val_loss: 0.0137 - val_mae: 0.0985\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0060 - mae: 0.0603 - val_loss: 0.0228 - val_mae: 0.1301\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0061 - mae: 0.0620 - val_loss: 0.0214 - val_mae: 0.1247\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0058 - mae: 0.0594 - val_loss: 0.0199 - val_mae: 0.1193\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0053 - mae: 0.0575 - val_loss: 0.0201 - val_mae: 0.1217\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0055 - mae: 0.0569 - val_loss: 0.0197 - val_mae: 0.1194\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0057 - mae: 0.0599 - val_loss: 0.0206 - val_mae: 0.1226\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 80, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 16ms/step - loss: 0.0340 - mae: 0.1447 - val_loss: 0.0175 - val_mae: 0.1068\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0192 - mae: 0.1113 - val_loss: 0.0203 - val_mae: 0.1143\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0154 - mae: 0.0987 - val_loss: 0.0314 - val_mae: 0.1437\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0128 - mae: 0.0902 - val_loss: 0.0377 - val_mae: 0.1628\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0116 - mae: 0.0860 - val_loss: 0.0332 - val_mae: 0.1472\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0095 - mae: 0.0784 - val_loss: 0.0459 - val_mae: 0.1777\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0101 - mae: 0.0794 - val_loss: 0.0552 - val_mae: 0.1957\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0086 - mae: 0.0730 - val_loss: 0.0539 - val_mae: 0.1941\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0092 - mae: 0.0762 - val_loss: 0.0604 - val_mae: 0.2105\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0084 - mae: 0.0729 - val_loss: 0.0463 - val_mae: 0.1843\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0074 - mae: 0.0682 - val_loss: 0.0644 - val_mae: 0.2185\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0087 - mae: 0.0742 - val_loss: 0.0868 - val_mae: 0.2587\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0079 - mae: 0.0715 - val_loss: 0.0526 - val_mae: 0.1952\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0087 - mae: 0.0737 - val_loss: 0.0565 - val_mae: 0.1998\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0075 - mae: 0.0677 - val_loss: 0.0662 - val_mae: 0.2211\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0079 - mae: 0.0701 - val_loss: 0.0441 - val_mae: 0.1770\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0078 - mae: 0.0702 - val_loss: 0.0498 - val_mae: 0.1922\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0075 - mae: 0.0692 - val_loss: 0.0678 - val_mae: 0.2290\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0076 - mae: 0.0682 - val_loss: 0.0626 - val_mae: 0.2161\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0073 - mae: 0.0665 - val_loss: 0.0703 - val_mae: 0.2313\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0070 - mae: 0.0665 - val_loss: 0.0587 - val_mae: 0.2076\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 160, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 17ms/step - loss: 0.0219 - mae: 0.1000 - val_loss: 0.0065 - val_mae: 0.0637\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0048 - mae: 0.0544 - val_loss: 0.0042 - val_mae: 0.0499\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0482 - val_loss: 0.0041 - val_mae: 0.0498\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0043 - mae: 0.0512 - val_loss: 0.0055 - val_mae: 0.0584\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0042 - mae: 0.0501 - val_loss: 0.0041 - val_mae: 0.0493\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0046 - mae: 0.0543 - val_loss: 0.0040 - val_mae: 0.0485\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0044 - mae: 0.0516 - val_loss: 0.0042 - val_mae: 0.0506\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0043 - mae: 0.0514 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0043 - mae: 0.0517 - val_loss: 0.0042 - val_mae: 0.0516\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0043 - val_mae: 0.0510\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0041 - mae: 0.0514 - val_loss: 0.0042 - val_mae: 0.0507\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0042 - val_mae: 0.0494\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0041 - mae: 0.0500 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0041 - val_mae: 0.0508\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0505 - val_loss: 0.0042 - val_mae: 0.0509\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0043 - mae: 0.0523 - val_loss: 0.0042 - val_mae: 0.0505\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0041 - val_mae: 0.0511\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0041 - mae: 0.0502 - val_loss: 0.0045 - val_mae: 0.0530\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0493 - val_loss: 0.0043 - val_mae: 0.0505\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0040 - val_mae: 0.0485\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0042 - val_mae: 0.0510\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0042 - mae: 0.0514 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0041 - mae: 0.0507 - val_loss: 0.0043 - val_mae: 0.0525\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0041 - mae: 0.0496 - val_loss: 0.0040 - val_mae: 0.0500\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0043 - mae: 0.0524 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0043 - mae: 0.0517 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0041 - mae: 0.0497 - val_loss: 0.0039 - val_mae: 0.0480\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0494\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0042 - val_mae: 0.0495\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0041 - val_mae: 0.0516\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0485\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0042 - val_mae: 0.0521\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0492 - val_loss: 0.0041 - val_mae: 0.0487\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0048 - val_mae: 0.0561\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0046 - val_mae: 0.0552\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0043 - mae: 0.0509 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0044 - val_mae: 0.0513\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0041 - mae: 0.0511 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0039 - val_mae: 0.0492\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0047 - val_mae: 0.0526\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0041 - val_mae: 0.0507\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 160, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 6s 21ms/step - loss: 0.0275 - mae: 0.1303 - val_loss: 0.0157 - val_mae: 0.1016\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0140 - mae: 0.0940 - val_loss: 0.0117 - val_mae: 0.0856\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0134 - mae: 0.0913 - val_loss: 0.0116 - val_mae: 0.0857\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0106 - mae: 0.0815 - val_loss: 0.0116 - val_mae: 0.0851\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0085 - mae: 0.0736 - val_loss: 0.0246 - val_mae: 0.1301\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0067 - mae: 0.0655 - val_loss: 0.0225 - val_mae: 0.1240\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0067 - mae: 0.0659 - val_loss: 0.0235 - val_mae: 0.1292\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0064 - mae: 0.0628 - val_loss: 0.0237 - val_mae: 0.1300\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0060 - mae: 0.0606 - val_loss: 0.0161 - val_mae: 0.1070\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0057 - mae: 0.0590 - val_loss: 0.0134 - val_mae: 0.0969\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0065 - mae: 0.0646 - val_loss: 0.0208 - val_mae: 0.1205\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0055 - mae: 0.0585 - val_loss: 0.0277 - val_mae: 0.1420\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 19ms/step - loss: 0.0055 - mae: 0.0586 - val_loss: 0.0216 - val_mae: 0.1270\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0057 - mae: 0.0586 - val_loss: 0.0225 - val_mae: 0.1276\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0057 - mae: 0.0588 - val_loss: 0.0218 - val_mae: 0.1258\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0063 - mae: 0.0624 - val_loss: 0.0204 - val_mae: 0.1224\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0054 - mae: 0.0573 - val_loss: 0.0218 - val_mae: 0.1254\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0052 - mae: 0.0564 - val_loss: 0.0251 - val_mae: 0.1353\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0055 - mae: 0.0585 - val_loss: 0.0252 - val_mae: 0.1368\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0059 - mae: 0.0604 - val_loss: 0.0296 - val_mae: 0.1478\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0054 - mae: 0.0581 - val_loss: 0.0172 - val_mae: 0.1107\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0058 - mae: 0.0593 - val_loss: 0.0182 - val_mae: 0.1131\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0055 - mae: 0.0591 - val_loss: 0.0302 - val_mae: 0.1502\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'GRU', 'units': 160, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 7s 24ms/step - loss: 0.0580 - mae: 0.1662 - val_loss: 0.0180 - val_mae: 0.1086\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0180 - mae: 0.1069 - val_loss: 0.0179 - val_mae: 0.1083\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0173 - mae: 0.1063 - val_loss: 0.0398 - val_mae: 0.1649\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0139 - mae: 0.0926 - val_loss: 0.0342 - val_mae: 0.1541\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0091 - mae: 0.0742 - val_loss: 0.0406 - val_mae: 0.1678\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0102 - mae: 0.0812 - val_loss: 0.0446 - val_mae: 0.1757\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0096 - mae: 0.0755 - val_loss: 0.0396 - val_mae: 0.1647\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0080 - mae: 0.0702 - val_loss: 0.0618 - val_mae: 0.2136\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0083 - mae: 0.0718 - val_loss: 0.0469 - val_mae: 0.1803\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0085 - mae: 0.0722 - val_loss: 0.0701 - val_mae: 0.2243\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0078 - mae: 0.0688 - val_loss: 0.0440 - val_mae: 0.1775\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0078 - mae: 0.0706 - val_loss: 0.0560 - val_mae: 0.2052\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0073 - mae: 0.0680 - val_loss: 0.0629 - val_mae: 0.2178\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0080 - mae: 0.0710 - val_loss: 0.0517 - val_mae: 0.1922\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0080 - mae: 0.0703 - val_loss: 0.0687 - val_mae: 0.2260\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0071 - mae: 0.0652 - val_loss: 0.0632 - val_mae: 0.2141\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0075 - mae: 0.0680 - val_loss: 0.0783 - val_mae: 0.2423\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0077 - mae: 0.0692 - val_loss: 0.0725 - val_mae: 0.2349\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0079 - mae: 0.0698 - val_loss: 0.0605 - val_mae: 0.2121\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0074 - mae: 0.0668 - val_loss: 0.0502 - val_mae: 0.1930\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0075 - mae: 0.0681 - val_loss: 0.0643 - val_mae: 0.2269\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0081 - mae: 0.0718 - val_loss: 0.0594 - val_mae: 0.2079\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 10, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 16ms/step - loss: 0.0406 - mae: 0.1461 - val_loss: 0.0108 - val_mae: 0.0831\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0089 - mae: 0.0748 - val_loss: 0.0105 - val_mae: 0.0813\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0089 - mae: 0.0746 - val_loss: 0.0099 - val_mae: 0.0793\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0083 - mae: 0.0722 - val_loss: 0.0106 - val_mae: 0.0817\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0082 - mae: 0.0721 - val_loss: 0.0103 - val_mae: 0.0823\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0077 - mae: 0.0702 - val_loss: 0.0093 - val_mae: 0.0758\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0077 - mae: 0.0700 - val_loss: 0.0089 - val_mae: 0.0756\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0068 - mae: 0.0650 - val_loss: 0.0086 - val_mae: 0.0740\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0067 - mae: 0.0655 - val_loss: 0.0086 - val_mae: 0.0731\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0069 - mae: 0.0652 - val_loss: 0.0087 - val_mae: 0.0745\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0065 - mae: 0.0645 - val_loss: 0.0074 - val_mae: 0.0687\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0057 - mae: 0.0606 - val_loss: 0.0071 - val_mae: 0.0669\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0054 - mae: 0.0571 - val_loss: 0.0064 - val_mae: 0.0636\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0049 - mae: 0.0557 - val_loss: 0.0059 - val_mae: 0.0610\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0048 - mae: 0.0545 - val_loss: 0.0059 - val_mae: 0.0616\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0044 - mae: 0.0524 - val_loss: 0.0052 - val_mae: 0.0576\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0041 - mae: 0.0501 - val_loss: 0.0047 - val_mae: 0.0545\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0046 - val_mae: 0.0532\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0042 - mae: 0.0510 - val_loss: 0.0046 - val_mae: 0.0530\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0041 - mae: 0.0505 - val_loss: 0.0050 - val_mae: 0.0566\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0041 - val_mae: 0.0500\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0043 - val_mae: 0.0507\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0042 - val_mae: 0.0503\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0042 - mae: 0.0506 - val_loss: 0.0044 - val_mae: 0.0519\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0042 - val_mae: 0.0513\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0044 - val_mae: 0.0535\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0043 - val_mae: 0.0526\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0041 - mae: 0.0512 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0043 - val_mae: 0.0509\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0042 - val_mae: 0.0501\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0043 - val_mae: 0.0530\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0464 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0042 - val_mae: 0.0500\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0503\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0035 - mae: 0.0464 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0039 - val_mae: 0.0493\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0041 - val_mae: 0.0507\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0042 - val_mae: 0.0523\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0499 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0041 - val_mae: 0.0498\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0043 - val_mae: 0.0526\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 54/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0039 - val_mae: 0.0495\n",
      "Epoch 55/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 56/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0041 - mae: 0.0498 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 57/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0462 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 58/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0041 - val_mae: 0.0506\n",
      "Epoch 59/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0477 - val_loss: 0.0041 - val_mae: 0.0508\n",
      "Epoch 60/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0495\n",
      "Epoch 61/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 62/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0043 - val_mae: 0.0509\n",
      "Epoch 63/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0481 - val_loss: 0.0040 - val_mae: 0.0497\n",
      "Epoch 64/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 65/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 66/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0040 - val_mae: 0.0500\n",
      "Epoch 67/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0036 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 68/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0034 - mae: 0.0462 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 69/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0035 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 70/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 71/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 72/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 73/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 74/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0039 - val_mae: 0.0488\n",
      "Epoch 75/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 76/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0041 - val_mae: 0.0496\n",
      "Epoch 77/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0041 - val_mae: 0.0508\n",
      "Epoch 78/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 79/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0488\n",
      "Epoch 80/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0035 - mae: 0.0462 - val_loss: 0.0042 - val_mae: 0.0501\n",
      "Epoch 81/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 82/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 83/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 84/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0041 - val_mae: 0.0506\n",
      "Epoch 85/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0043 - val_mae: 0.0508\n",
      "Epoch 86/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0041 - val_mae: 0.0506\n",
      "Epoch 87/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0470 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 88/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 89/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0468 - val_loss: 0.0042 - val_mae: 0.0519\n",
      "Epoch 90/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0041 - val_mae: 0.0496\n",
      "Epoch 91/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 10, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 7s 24ms/step - loss: 0.1302 - mae: 0.2554 - val_loss: 0.0149 - val_mae: 0.0969\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0139 - mae: 0.0923 - val_loss: 0.0127 - val_mae: 0.0900\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0135 - mae: 0.0933 - val_loss: 0.0122 - val_mae: 0.0872\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0131 - mae: 0.0914 - val_loss: 0.0158 - val_mae: 0.1014\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0133 - mae: 0.0905 - val_loss: 0.0123 - val_mae: 0.0885\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0122 - mae: 0.0874 - val_loss: 0.0117 - val_mae: 0.0861\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0122 - mae: 0.0884 - val_loss: 0.0117 - val_mae: 0.0858\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0115 - mae: 0.0862 - val_loss: 0.0116 - val_mae: 0.0852\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0127 - mae: 0.0889 - val_loss: 0.0110 - val_mae: 0.0834\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0117 - mae: 0.0864 - val_loss: 0.0109 - val_mae: 0.0825\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0105 - mae: 0.0819 - val_loss: 0.0132 - val_mae: 0.0923\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0120 - mae: 0.0869 - val_loss: 0.0108 - val_mae: 0.0825\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0114 - mae: 0.0847 - val_loss: 0.0103 - val_mae: 0.0812\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0126 - mae: 0.0887 - val_loss: 0.0102 - val_mae: 0.0797\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0105 - mae: 0.0804 - val_loss: 0.0105 - val_mae: 0.0806\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0114 - mae: 0.0860 - val_loss: 0.0117 - val_mae: 0.0861\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0107 - mae: 0.0834 - val_loss: 0.0109 - val_mae: 0.0827\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0115 - mae: 0.0844 - val_loss: 0.0102 - val_mae: 0.0795\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0094 - mae: 0.0781 - val_loss: 0.0095 - val_mae: 0.0769\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0106 - mae: 0.0812 - val_loss: 0.0124 - val_mae: 0.0908\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0106 - mae: 0.0814 - val_loss: 0.0095 - val_mae: 0.0772\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0092 - mae: 0.0750 - val_loss: 0.0092 - val_mae: 0.0755\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0106 - mae: 0.0816 - val_loss: 0.0097 - val_mae: 0.0794\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0093 - mae: 0.0767 - val_loss: 0.0091 - val_mae: 0.0761\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0098 - mae: 0.0803 - val_loss: 0.0099 - val_mae: 0.0798\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0087 - mae: 0.0735 - val_loss: 0.0093 - val_mae: 0.0763\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0101 - mae: 0.0801 - val_loss: 0.0095 - val_mae: 0.0774\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0094 - mae: 0.0777 - val_loss: 0.0091 - val_mae: 0.0751\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0097 - mae: 0.0782 - val_loss: 0.0100 - val_mae: 0.0788\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0090 - mae: 0.0756 - val_loss: 0.0099 - val_mae: 0.0788\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0092 - mae: 0.0755 - val_loss: 0.0098 - val_mae: 0.0789\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0090 - mae: 0.0743 - val_loss: 0.0097 - val_mae: 0.0775\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0094 - mae: 0.0770 - val_loss: 0.0097 - val_mae: 0.0778\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0091 - mae: 0.0760 - val_loss: 0.0099 - val_mae: 0.0791\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0096 - mae: 0.0772 - val_loss: 0.0092 - val_mae: 0.0755\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0092 - mae: 0.0762 - val_loss: 0.0107 - val_mae: 0.0813\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0083 - mae: 0.0730 - val_loss: 0.0120 - val_mae: 0.0882\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0089 - mae: 0.0746 - val_loss: 0.0137 - val_mae: 0.0929\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0095 - mae: 0.0772 - val_loss: 0.0103 - val_mae: 0.0807\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0083 - mae: 0.0717 - val_loss: 0.0098 - val_mae: 0.0776\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 3s 19ms/step - loss: 0.0078 - mae: 0.0698 - val_loss: 0.0099 - val_mae: 0.0792\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0080 - mae: 0.0706 - val_loss: 0.0115 - val_mae: 0.0852\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0077 - mae: 0.0693 - val_loss: 0.0124 - val_mae: 0.0897\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0086 - mae: 0.0741 - val_loss: 0.0150 - val_mae: 0.1000\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0075 - mae: 0.0676 - val_loss: 0.0130 - val_mae: 0.0919\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0083 - mae: 0.0713 - val_loss: 0.0106 - val_mae: 0.0821\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0068 - mae: 0.0648 - val_loss: 0.0097 - val_mae: 0.0783\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0078 - mae: 0.0702 - val_loss: 0.0121 - val_mae: 0.0886\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 10, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 16ms/step - loss: 0.0861 - mae: 0.2301 - val_loss: 0.0163 - val_mae: 0.1017\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0162 - mae: 0.1015 - val_loss: 0.0136 - val_mae: 0.0918\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0156 - mae: 0.0984 - val_loss: 0.0134 - val_mae: 0.0918\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0150 - mae: 0.0966 - val_loss: 0.0121 - val_mae: 0.0872\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0145 - mae: 0.0956 - val_loss: 0.0127 - val_mae: 0.0890\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0138 - mae: 0.0923 - val_loss: 0.0143 - val_mae: 0.0960\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0146 - mae: 0.0951 - val_loss: 0.0125 - val_mae: 0.0882\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0153 - mae: 0.0974 - val_loss: 0.0141 - val_mae: 0.0945\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0142 - mae: 0.0922 - val_loss: 0.0120 - val_mae: 0.0866\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0141 - mae: 0.0935 - val_loss: 0.0170 - val_mae: 0.1043\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0149 - mae: 0.0972 - val_loss: 0.0131 - val_mae: 0.0913\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0139 - mae: 0.0931 - val_loss: 0.0127 - val_mae: 0.0892\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0128 - mae: 0.0908 - val_loss: 0.0146 - val_mae: 0.0959\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0135 - mae: 0.0918 - val_loss: 0.0183 - val_mae: 0.1086\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0121 - mae: 0.0862 - val_loss: 0.0204 - val_mae: 0.1160\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0119 - mae: 0.0850 - val_loss: 0.0186 - val_mae: 0.1097\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0118 - mae: 0.0847 - val_loss: 0.0186 - val_mae: 0.1096\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0120 - mae: 0.0859 - val_loss: 0.0194 - val_mae: 0.1115\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0118 - mae: 0.0856 - val_loss: 0.0169 - val_mae: 0.1031\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0119 - mae: 0.0858 - val_loss: 0.0238 - val_mae: 0.1248\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0113 - mae: 0.0824 - val_loss: 0.0348 - val_mae: 0.1555\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0127 - mae: 0.0888 - val_loss: 0.0411 - val_mae: 0.1702\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0110 - mae: 0.0827 - val_loss: 0.0253 - val_mae: 0.1281\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0104 - mae: 0.0802 - val_loss: 0.0316 - val_mae: 0.1464\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0111 - mae: 0.0832 - val_loss: 0.0320 - val_mae: 0.1469\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0106 - mae: 0.0816 - val_loss: 0.0418 - val_mae: 0.1684\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0099 - mae: 0.0790 - val_loss: 0.0582 - val_mae: 0.2007\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0086 - mae: 0.0732 - val_loss: 0.0433 - val_mae: 0.1720\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0099 - mae: 0.0786 - val_loss: 0.0486 - val_mae: 0.1818\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 20, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 16ms/step - loss: 0.0602 - mae: 0.1776 - val_loss: 0.0107 - val_mae: 0.0838\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0087 - mae: 0.0741 - val_loss: 0.0108 - val_mae: 0.0841\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0087 - mae: 0.0736 - val_loss: 0.0105 - val_mae: 0.0814\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0081 - mae: 0.0715 - val_loss: 0.0101 - val_mae: 0.0796\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0073 - mae: 0.0672 - val_loss: 0.0093 - val_mae: 0.0767\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0077 - mae: 0.0700 - val_loss: 0.0088 - val_mae: 0.0745\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0075 - mae: 0.0691 - val_loss: 0.0084 - val_mae: 0.0724\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0067 - mae: 0.0649 - val_loss: 0.0088 - val_mae: 0.0754\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0067 - mae: 0.0655 - val_loss: 0.0070 - val_mae: 0.0670\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0055 - mae: 0.0589 - val_loss: 0.0064 - val_mae: 0.0635\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0050 - mae: 0.0561 - val_loss: 0.0059 - val_mae: 0.0605\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0047 - mae: 0.0531 - val_loss: 0.0052 - val_mae: 0.0567\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0041 - mae: 0.0508 - val_loss: 0.0047 - val_mae: 0.0537\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0052 - val_mae: 0.0583\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0043 - val_mae: 0.0519\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0043 - val_mae: 0.0515\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0048 - val_mae: 0.0562\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0040 - mae: 0.0501 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 0.0041 - val_mae: 0.0503\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0042 - val_mae: 0.0503\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0052 - val_mae: 0.0586\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0041 - val_mae: 0.0506\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0034 - mae: 0.0453 - val_loss: 0.0042 - val_mae: 0.0503\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0042 - val_mae: 0.0515\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0476 - val_loss: 0.0041 - val_mae: 0.0490\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0480\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0043 - val_mae: 0.0508\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0040 - val_mae: 0.0498\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0040 - mae: 0.0498 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0495\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0038 - val_mae: 0.0478\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0485\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0041 - val_mae: 0.0500\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0036 - mae: 0.0469 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0038 - val_mae: 0.0480\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0034 - mae: 0.0461 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0039 - val_mae: 0.0479\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 54/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0041 - val_mae: 0.0510\n",
      "Epoch 55/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0041 - val_mae: 0.0504\n",
      "Epoch 56/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 57/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0038 - val_mae: 0.0480\n",
      "Epoch 58/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0034 - mae: 0.0456 - val_loss: 0.0038 - val_mae: 0.0483\n",
      "Epoch 59/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 60/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0036 - mae: 0.0479 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 61/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 62/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 63/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 64/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 65/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0039 - val_mae: 0.0489\n",
      "Epoch 66/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 67/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 68/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 69/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 70/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0468 - val_loss: 0.0038 - val_mae: 0.0479\n",
      "Epoch 71/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0033 - mae: 0.0456 - val_loss: 0.0089 - val_mae: 0.0724\n",
      "Epoch 72/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0043 - mae: 0.0503 - val_loss: 0.0041 - val_mae: 0.0512\n",
      "Epoch 73/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0490\n",
      "Epoch 74/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 75/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0469 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 76/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0034 - mae: 0.0463 - val_loss: 0.0038 - val_mae: 0.0476\n",
      "Epoch 77/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0038 - val_mae: 0.0479\n",
      "Epoch 78/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0042 - val_mae: 0.0515\n",
      "Epoch 79/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0038 - val_mae: 0.0478\n",
      "Epoch 80/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 81/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 82/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0033 - mae: 0.0451 - val_loss: 0.0038 - val_mae: 0.0481\n",
      "Epoch 83/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0036 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0492\n",
      "Epoch 84/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0464 - val_loss: 0.0039 - val_mae: 0.0488\n",
      "Epoch 85/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0463 - val_loss: 0.0040 - val_mae: 0.0501\n",
      "Epoch 86/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 87/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0488 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 88/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0038 - val_mae: 0.0480\n",
      "Epoch 89/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 90/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0038 - val_mae: 0.0477\n",
      "Epoch 91/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0034 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0481\n",
      "Epoch 92/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 93/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0041 - val_mae: 0.0493\n",
      "Epoch 94/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0034 - mae: 0.0460 - val_loss: 0.0038 - val_mae: 0.0482\n",
      "Epoch 95/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0035 - mae: 0.0467 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 96/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0468 - val_loss: 0.0039 - val_mae: 0.0493\n",
      "Epoch 97/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0035 - mae: 0.0461 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 20, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 6s 16ms/step - loss: 0.0353 - mae: 0.1372 - val_loss: 0.0135 - val_mae: 0.0934\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0133 - mae: 0.0901 - val_loss: 0.0128 - val_mae: 0.0905\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0133 - mae: 0.0915 - val_loss: 0.0117 - val_mae: 0.0852\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0110 - mae: 0.0834 - val_loss: 0.0121 - val_mae: 0.0888\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0116 - mae: 0.0859 - val_loss: 0.0105 - val_mae: 0.0811\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0116 - mae: 0.0854 - val_loss: 0.0108 - val_mae: 0.0819\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0113 - mae: 0.0826 - val_loss: 0.0116 - val_mae: 0.0861\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0118 - mae: 0.0855 - val_loss: 0.0106 - val_mae: 0.0817\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0111 - mae: 0.0857 - val_loss: 0.0102 - val_mae: 0.0795\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0102 - mae: 0.0793 - val_loss: 0.0102 - val_mae: 0.0795\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0102 - mae: 0.0803 - val_loss: 0.0100 - val_mae: 0.0795\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0107 - mae: 0.0827 - val_loss: 0.0148 - val_mae: 0.1007\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0105 - mae: 0.0820 - val_loss: 0.0099 - val_mae: 0.0784\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0106 - mae: 0.0809 - val_loss: 0.0100 - val_mae: 0.0787\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0102 - mae: 0.0803 - val_loss: 0.0100 - val_mae: 0.0785\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0105 - mae: 0.0791 - val_loss: 0.0114 - val_mae: 0.0845\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0103 - mae: 0.0801 - val_loss: 0.0097 - val_mae: 0.0775\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0092 - mae: 0.0758 - val_loss: 0.0131 - val_mae: 0.0916\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0099 - mae: 0.0788 - val_loss: 0.0089 - val_mae: 0.0750\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0091 - mae: 0.0756 - val_loss: 0.0095 - val_mae: 0.0772\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0094 - mae: 0.0767 - val_loss: 0.0107 - val_mae: 0.0818\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0090 - mae: 0.0746 - val_loss: 0.0094 - val_mae: 0.0761\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0085 - mae: 0.0720 - val_loss: 0.0122 - val_mae: 0.0882\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0087 - mae: 0.0750 - val_loss: 0.0113 - val_mae: 0.0841\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0089 - mae: 0.0743 - val_loss: 0.0095 - val_mae: 0.0774\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0090 - mae: 0.0741 - val_loss: 0.0195 - val_mae: 0.1153\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0079 - mae: 0.0705 - val_loss: 0.0146 - val_mae: 0.0984\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0086 - mae: 0.0729 - val_loss: 0.0129 - val_mae: 0.0917\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0085 - mae: 0.0722 - val_loss: 0.0190 - val_mae: 0.1140\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0083 - mae: 0.0727 - val_loss: 0.0138 - val_mae: 0.0954\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0080 - mae: 0.0723 - val_loss: 0.0141 - val_mae: 0.0963\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0073 - mae: 0.0680 - val_loss: 0.0125 - val_mae: 0.0892\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0076 - mae: 0.0681 - val_loss: 0.0168 - val_mae: 0.1067\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0073 - mae: 0.0675 - val_loss: 0.0163 - val_mae: 0.1053\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0072 - mae: 0.0676 - val_loss: 0.0115 - val_mae: 0.0868\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0072 - mae: 0.0676 - val_loss: 0.0130 - val_mae: 0.0914\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0071 - mae: 0.0659 - val_loss: 0.0172 - val_mae: 0.1084\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0069 - mae: 0.0661 - val_loss: 0.0182 - val_mae: 0.1115\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0070 - mae: 0.0662 - val_loss: 0.0162 - val_mae: 0.1053\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 20, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 5s 16ms/step - loss: 0.0509 - mae: 0.1696 - val_loss: 0.0157 - val_mae: 0.0989\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0176 - mae: 0.1053 - val_loss: 0.0147 - val_mae: 0.0973\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0161 - mae: 0.1011 - val_loss: 0.0132 - val_mae: 0.0909\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0152 - mae: 0.0968 - val_loss: 0.0134 - val_mae: 0.0922\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0154 - mae: 0.0976 - val_loss: 0.0120 - val_mae: 0.0863\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0135 - mae: 0.0910 - val_loss: 0.0131 - val_mae: 0.0904\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0147 - mae: 0.0959 - val_loss: 0.0131 - val_mae: 0.0914\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0145 - mae: 0.0943 - val_loss: 0.0187 - val_mae: 0.1091\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0130 - mae: 0.0905 - val_loss: 0.0154 - val_mae: 0.0983\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0119 - mae: 0.0879 - val_loss: 0.0134 - val_mae: 0.0920\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0129 - mae: 0.0906 - val_loss: 0.0241 - val_mae: 0.1260\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0109 - mae: 0.0829 - val_loss: 0.0290 - val_mae: 0.1413\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0101 - mae: 0.0802 - val_loss: 0.0223 - val_mae: 0.1197\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0107 - mae: 0.0841 - val_loss: 0.0178 - val_mae: 0.1070\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0100 - mae: 0.0788 - val_loss: 0.0416 - val_mae: 0.1728\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0101 - mae: 0.0803 - val_loss: 0.0243 - val_mae: 0.1277\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0090 - mae: 0.0757 - val_loss: 0.0424 - val_mae: 0.1752\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0093 - mae: 0.0755 - val_loss: 0.0415 - val_mae: 0.1720\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0089 - mae: 0.0743 - val_loss: 0.0307 - val_mae: 0.1438\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0097 - mae: 0.0768 - val_loss: 0.0319 - val_mae: 0.1495\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0091 - mae: 0.0755 - val_loss: 0.0440 - val_mae: 0.1778\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0091 - mae: 0.0764 - val_loss: 0.0475 - val_mae: 0.1863\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0097 - mae: 0.0777 - val_loss: 0.0509 - val_mae: 0.1931\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0094 - mae: 0.0758 - val_loss: 0.0518 - val_mae: 0.1949\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0079 - mae: 0.0703 - val_loss: 0.0433 - val_mae: 0.1757\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 40, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 6s 16ms/step - loss: 0.0483 - mae: 0.1593 - val_loss: 0.0126 - val_mae: 0.0917\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0093 - mae: 0.0771 - val_loss: 0.0105 - val_mae: 0.0831\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0073 - mae: 0.0677 - val_loss: 0.0091 - val_mae: 0.0753\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0071 - mae: 0.0664 - val_loss: 0.0084 - val_mae: 0.0719\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0061 - mae: 0.0626 - val_loss: 0.0072 - val_mae: 0.0681\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0060 - mae: 0.0625 - val_loss: 0.0075 - val_mae: 0.0683\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0052 - mae: 0.0572 - val_loss: 0.0076 - val_mae: 0.0698\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0049 - mae: 0.0558 - val_loss: 0.0053 - val_mae: 0.0580\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0044 - mae: 0.0533 - val_loss: 0.0046 - val_mae: 0.0536\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0043 - mae: 0.0516 - val_loss: 0.0043 - val_mae: 0.0510\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0053 - val_mae: 0.0589\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0041 - mae: 0.0504 - val_loss: 0.0046 - val_mae: 0.0525\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0042 - val_mae: 0.0500\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0047 - val_mae: 0.0551\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0044 - val_mae: 0.0514\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0481 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0041 - val_mae: 0.0503\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0490 - val_loss: 0.0041 - val_mae: 0.0497\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0043 - val_mae: 0.0500\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0041 - val_mae: 0.0496\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0041 - val_mae: 0.0496\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0042 - val_mae: 0.0506\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0041 - mae: 0.0498 - val_loss: 0.0042 - val_mae: 0.0512\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0486 - val_loss: 0.0040 - val_mae: 0.0483\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0041 - val_mae: 0.0494\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0040 - val_mae: 0.0500\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0035 - mae: 0.0471 - val_loss: 0.0046 - val_mae: 0.0527\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0045 - val_mae: 0.0517\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0043 - val_mae: 0.0508\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0050 - val_mae: 0.0554\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0504\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0044 - val_mae: 0.0526\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0040 - val_mae: 0.0498\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0037 - mae: 0.0474 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0043 - val_mae: 0.0529\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0041 - val_mae: 0.0489\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 3s 19ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 40, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 6s 17ms/step - loss: 0.0265 - mae: 0.1252 - val_loss: 0.0140 - val_mae: 0.0956\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0125 - mae: 0.0900 - val_loss: 0.0107 - val_mae: 0.0824\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0118 - mae: 0.0870 - val_loss: 0.0114 - val_mae: 0.0859\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0110 - mae: 0.0832 - val_loss: 0.0098 - val_mae: 0.0775\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0103 - mae: 0.0798 - val_loss: 0.0104 - val_mae: 0.0805\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0120 - mae: 0.0869 - val_loss: 0.0114 - val_mae: 0.0844\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0114 - mae: 0.0844 - val_loss: 0.0131 - val_mae: 0.0912\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0111 - mae: 0.0833 - val_loss: 0.0111 - val_mae: 0.0848\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0102 - mae: 0.0798 - val_loss: 0.0115 - val_mae: 0.0855\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0110 - mae: 0.0834 - val_loss: 0.0102 - val_mae: 0.0799\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0107 - mae: 0.0826 - val_loss: 0.0091 - val_mae: 0.0762\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0105 - mae: 0.0818 - val_loss: 0.0097 - val_mae: 0.0771\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0091 - mae: 0.0747 - val_loss: 0.0105 - val_mae: 0.0806\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0088 - mae: 0.0735 - val_loss: 0.0099 - val_mae: 0.0788\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0095 - mae: 0.0779 - val_loss: 0.0085 - val_mae: 0.0728\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0098 - mae: 0.0782 - val_loss: 0.0117 - val_mae: 0.0855\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0088 - mae: 0.0745 - val_loss: 0.0088 - val_mae: 0.0741\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0087 - mae: 0.0747 - val_loss: 0.0127 - val_mae: 0.0899\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0096 - mae: 0.0782 - val_loss: 0.0145 - val_mae: 0.0982\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0088 - mae: 0.0741 - val_loss: 0.0114 - val_mae: 0.0843\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0080 - mae: 0.0705 - val_loss: 0.0160 - val_mae: 0.1034\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0075 - mae: 0.0690 - val_loss: 0.0149 - val_mae: 0.0993\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0076 - mae: 0.0695 - val_loss: 0.0141 - val_mae: 0.0948\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0084 - mae: 0.0733 - val_loss: 0.0128 - val_mae: 0.0901\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0074 - mae: 0.0672 - val_loss: 0.0181 - val_mae: 0.1117\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0068 - mae: 0.0650 - val_loss: 0.0112 - val_mae: 0.0848\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0070 - mae: 0.0669 - val_loss: 0.0126 - val_mae: 0.0910\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0068 - mae: 0.0659 - val_loss: 0.0143 - val_mae: 0.0980\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0070 - mae: 0.0665 - val_loss: 0.0154 - val_mae: 0.1023\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0067 - mae: 0.0638 - val_loss: 0.0216 - val_mae: 0.1250\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0069 - mae: 0.0656 - val_loss: 0.0175 - val_mae: 0.1103\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0069 - mae: 0.0650 - val_loss: 0.0181 - val_mae: 0.1129\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0070 - mae: 0.0671 - val_loss: 0.0176 - val_mae: 0.1112\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0059 - mae: 0.0600 - val_loss: 0.0165 - val_mae: 0.1069\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0063 - mae: 0.0625 - val_loss: 0.0148 - val_mae: 0.1010\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 40, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 6s 17ms/step - loss: 0.0554 - mae: 0.1747 - val_loss: 0.0174 - val_mae: 0.1047\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0194 - mae: 0.1113 - val_loss: 0.0143 - val_mae: 0.0952\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0143 - mae: 0.0952 - val_loss: 0.0119 - val_mae: 0.0866\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0161 - mae: 0.1014 - val_loss: 0.0113 - val_mae: 0.0852\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0143 - mae: 0.0950 - val_loss: 0.0115 - val_mae: 0.0853\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0149 - mae: 0.0957 - val_loss: 0.0125 - val_mae: 0.0886\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 19ms/step - loss: 0.0136 - mae: 0.0919 - val_loss: 0.0129 - val_mae: 0.0902\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0139 - mae: 0.0929 - val_loss: 0.0109 - val_mae: 0.0825\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0150 - mae: 0.0961 - val_loss: 0.0104 - val_mae: 0.0809\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0130 - mae: 0.0897 - val_loss: 0.0141 - val_mae: 0.0948\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0124 - mae: 0.0892 - val_loss: 0.0130 - val_mae: 0.0906\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0125 - mae: 0.0886 - val_loss: 0.0141 - val_mae: 0.0948\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0130 - mae: 0.0905 - val_loss: 0.0219 - val_mae: 0.1194\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0107 - mae: 0.0837 - val_loss: 0.0197 - val_mae: 0.1118\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 2s 12ms/step - loss: 0.0109 - mae: 0.0830 - val_loss: 0.0300 - val_mae: 0.1427\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0103 - mae: 0.0803 - val_loss: 0.0428 - val_mae: 0.1736\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0098 - mae: 0.0771 - val_loss: 0.0440 - val_mae: 0.1749\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0104 - mae: 0.0808 - val_loss: 0.0398 - val_mae: 0.1692\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0093 - mae: 0.0761 - val_loss: 0.0412 - val_mae: 0.1714\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0085 - mae: 0.0728 - val_loss: 0.0513 - val_mae: 0.1914\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0087 - mae: 0.0727 - val_loss: 0.0532 - val_mae: 0.2003\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0101 - mae: 0.0797 - val_loss: 0.0396 - val_mae: 0.1682\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 19ms/step - loss: 0.0092 - mae: 0.0758 - val_loss: 0.0476 - val_mae: 0.1875\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0100 - mae: 0.0809 - val_loss: 0.0510 - val_mae: 0.1913\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0092 - mae: 0.0769 - val_loss: 0.0692 - val_mae: 0.2300\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0085 - mae: 0.0726 - val_loss: 0.0502 - val_mae: 0.1935\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0077 - mae: 0.0688 - val_loss: 0.0524 - val_mae: 0.1926\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0086 - mae: 0.0729 - val_loss: 0.0369 - val_mae: 0.1624\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0083 - mae: 0.0729 - val_loss: 0.0588 - val_mae: 0.2068\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 80, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 6s 18ms/step - loss: 0.0228 - mae: 0.1103 - val_loss: 0.0100 - val_mae: 0.0783\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0087 - mae: 0.0745 - val_loss: 0.0084 - val_mae: 0.0721\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0068 - mae: 0.0656 - val_loss: 0.0076 - val_mae: 0.0694\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0059 - mae: 0.0613 - val_loss: 0.0064 - val_mae: 0.0636\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0055 - mae: 0.0588 - val_loss: 0.0066 - val_mae: 0.0657\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0049 - mae: 0.0558 - val_loss: 0.0046 - val_mae: 0.0531\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0063 - val_mae: 0.0636\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0043 - mae: 0.0519 - val_loss: 0.0054 - val_mae: 0.0594\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0043 - val_mae: 0.0504\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0041 - val_mae: 0.0500\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0041 - val_mae: 0.0502\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0052 - val_mae: 0.0585\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0497 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0043 - val_mae: 0.0522\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0041 - val_mae: 0.0504\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0045 - val_mae: 0.0540\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0042 - val_mae: 0.0513\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0041 - mae: 0.0501 - val_loss: 0.0050 - val_mae: 0.0577\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0042 - mae: 0.0515 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0494 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0041 - mae: 0.0505 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0042 - mae: 0.0508 - val_loss: 0.0041 - val_mae: 0.0506\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0041 - val_mae: 0.0511\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0039 - val_mae: 0.0492\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0044 - val_mae: 0.0511\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0041 - val_mae: 0.0505\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0482 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0041 - mae: 0.0501 - val_loss: 0.0043 - val_mae: 0.0506\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0040 - mae: 0.0498 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0041 - val_mae: 0.0499\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0036 - mae: 0.0470 - val_loss: 0.0041 - val_mae: 0.0486\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0041 - val_mae: 0.0507\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0042 - val_mae: 0.0499\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0502\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0481 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0470 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 2s 13ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0048 - val_mae: 0.0539\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 3s 19ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0045 - val_mae: 0.0518\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 80, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 8s 22ms/step - loss: 0.0264 - mae: 0.1206 - val_loss: 0.0127 - val_mae: 0.0897\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0151 - mae: 0.0971 - val_loss: 0.0105 - val_mae: 0.0802\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0124 - mae: 0.0878 - val_loss: 0.0099 - val_mae: 0.0799\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0105 - mae: 0.0829 - val_loss: 0.0124 - val_mae: 0.0890\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0112 - mae: 0.0836 - val_loss: 0.0107 - val_mae: 0.0809\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0115 - mae: 0.0852 - val_loss: 0.0126 - val_mae: 0.0916\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0118 - mae: 0.0868 - val_loss: 0.0124 - val_mae: 0.0890\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0115 - mae: 0.0848 - val_loss: 0.0094 - val_mae: 0.0763\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0117 - mae: 0.0844 - val_loss: 0.0099 - val_mae: 0.0781\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0104 - mae: 0.0804 - val_loss: 0.0099 - val_mae: 0.0785\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0111 - mae: 0.0833 - val_loss: 0.0122 - val_mae: 0.0873\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0108 - mae: 0.0832 - val_loss: 0.0102 - val_mae: 0.0795\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0104 - mae: 0.0806 - val_loss: 0.0088 - val_mae: 0.0740\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0094 - mae: 0.0777 - val_loss: 0.0111 - val_mae: 0.0831\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 4s 22ms/step - loss: 0.0089 - mae: 0.0757 - val_loss: 0.0139 - val_mae: 0.0952\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0082 - mae: 0.0719 - val_loss: 0.0163 - val_mae: 0.1046\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0075 - mae: 0.0691 - val_loss: 0.0106 - val_mae: 0.0817\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0079 - mae: 0.0707 - val_loss: 0.0207 - val_mae: 0.1198\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0075 - mae: 0.0693 - val_loss: 0.0160 - val_mae: 0.1042\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0075 - mae: 0.0690 - val_loss: 0.0178 - val_mae: 0.1105\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0073 - mae: 0.0657 - val_loss: 0.0191 - val_mae: 0.1143\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0073 - mae: 0.0674 - val_loss: 0.0195 - val_mae: 0.1160\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0065 - mae: 0.0638 - val_loss: 0.0143 - val_mae: 0.0985\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0065 - mae: 0.0628 - val_loss: 0.0170 - val_mae: 0.1095\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0059 - mae: 0.0608 - val_loss: 0.0207 - val_mae: 0.1221\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0064 - mae: 0.0635 - val_loss: 0.0184 - val_mae: 0.1145\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0061 - mae: 0.0617 - val_loss: 0.0179 - val_mae: 0.1128\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0065 - mae: 0.0628 - val_loss: 0.0193 - val_mae: 0.1182\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0063 - mae: 0.0633 - val_loss: 0.0178 - val_mae: 0.1138\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0061 - mae: 0.0614 - val_loss: 0.0211 - val_mae: 0.1241\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0063 - mae: 0.0621 - val_loss: 0.0194 - val_mae: 0.1194\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0057 - mae: 0.0575 - val_loss: 0.0190 - val_mae: 0.1178\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0066 - mae: 0.0637 - val_loss: 0.0208 - val_mae: 0.1233\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 80, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 6s 17ms/step - loss: 0.0262 - mae: 0.1161 - val_loss: 0.0321 - val_mae: 0.1537\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0206 - mae: 0.1140 - val_loss: 0.0116 - val_mae: 0.0851\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0154 - mae: 0.0996 - val_loss: 0.0127 - val_mae: 0.0893\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0160 - mae: 0.1004 - val_loss: 0.0123 - val_mae: 0.0881\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0156 - mae: 0.0983 - val_loss: 0.0131 - val_mae: 0.0907\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0160 - mae: 0.0995 - val_loss: 0.0120 - val_mae: 0.0868\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0147 - mae: 0.0971 - val_loss: 0.0214 - val_mae: 0.1181\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0152 - mae: 0.0978 - val_loss: 0.0140 - val_mae: 0.0939\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0136 - mae: 0.0920 - val_loss: 0.0191 - val_mae: 0.1097\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0134 - mae: 0.0910 - val_loss: 0.0400 - val_mae: 0.1691\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0097 - mae: 0.0775 - val_loss: 0.0532 - val_mae: 0.1958\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0110 - mae: 0.0831 - val_loss: 0.0558 - val_mae: 0.2033\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0097 - mae: 0.0776 - val_loss: 0.0294 - val_mae: 0.1388\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0098 - mae: 0.0772 - val_loss: 0.0465 - val_mae: 0.1825\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0084 - mae: 0.0727 - val_loss: 0.0536 - val_mae: 0.1976\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 13ms/step - loss: 0.0093 - mae: 0.0776 - val_loss: 0.0706 - val_mae: 0.2257\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0085 - mae: 0.0721 - val_loss: 0.0587 - val_mae: 0.2075\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0084 - mae: 0.0725 - val_loss: 0.0663 - val_mae: 0.2218\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0088 - mae: 0.0745 - val_loss: 0.0607 - val_mae: 0.2098\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0090 - mae: 0.0763 - val_loss: 0.0770 - val_mae: 0.2377\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0092 - mae: 0.0762 - val_loss: 0.0793 - val_mae: 0.2474\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0097 - mae: 0.0789 - val_loss: 0.0596 - val_mae: 0.2068\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 160, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 7s 23ms/step - loss: 0.0203 - mae: 0.1045 - val_loss: 0.0129 - val_mae: 0.0918\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0080 - mae: 0.0717 - val_loss: 0.0075 - val_mae: 0.0690\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0061 - mae: 0.0609 - val_loss: 0.0064 - val_mae: 0.0631\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0057 - mae: 0.0595 - val_loss: 0.0054 - val_mae: 0.0584\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0052 - val_mae: 0.0563\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0043 - mae: 0.0517 - val_loss: 0.0042 - val_mae: 0.0502\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0043 - val_mae: 0.0509\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0042 - mae: 0.0510 - val_loss: 0.0041 - val_mae: 0.0500\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0042 - val_mae: 0.0497\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0043 - mae: 0.0517 - val_loss: 0.0040 - val_mae: 0.0497\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0045 - mae: 0.0529 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0044 - val_mae: 0.0517\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0500 - val_loss: 0.0043 - val_mae: 0.0514\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0046 - val_mae: 0.0525\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0045 - mae: 0.0534 - val_loss: 0.0042 - val_mae: 0.0515\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0040 - mae: 0.0502 - val_loss: 0.0045 - val_mae: 0.0542\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0046 - val_mae: 0.0529\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0503 - val_loss: 0.0044 - val_mae: 0.0515\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0057 - val_mae: 0.0597\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0040 - val_mae: 0.0485\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0494 - val_loss: 0.0041 - val_mae: 0.0502\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0040 - val_mae: 0.0498\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0045 - val_mae: 0.0537\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0040 - mae: 0.0495 - val_loss: 0.0045 - val_mae: 0.0519\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 0.0042 - val_mae: 0.0500\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0036 - mae: 0.0472 - val_loss: 0.0041 - val_mae: 0.0500\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0040 - mae: 0.0488 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0045 - val_mae: 0.0540\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0040 - val_mae: 0.0497\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0041 - val_mae: 0.0500\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0040 - mae: 0.0493 - val_loss: 0.0041 - val_mae: 0.0507\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0044 - val_mae: 0.0533\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0041 - val_mae: 0.0489\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0036 - mae: 0.0460 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0041 - val_mae: 0.0507\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0041 - val_mae: 0.0498\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0489 - val_loss: 0.0045 - val_mae: 0.0535\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0043 - val_mae: 0.0520\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0036 - mae: 0.0479 - val_loss: 0.0044 - val_mae: 0.0533\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 160, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 6s 18ms/step - loss: 0.0378 - mae: 0.1378 - val_loss: 0.0164 - val_mae: 0.1044\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0132 - mae: 0.0909 - val_loss: 0.0101 - val_mae: 0.0804\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 19ms/step - loss: 0.0143 - mae: 0.0956 - val_loss: 0.0110 - val_mae: 0.0831\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0119 - mae: 0.0864 - val_loss: 0.0110 - val_mae: 0.0825\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0105 - mae: 0.0800 - val_loss: 0.0116 - val_mae: 0.0853\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0120 - mae: 0.0863 - val_loss: 0.0091 - val_mae: 0.0743\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0116 - mae: 0.0861 - val_loss: 0.0105 - val_mae: 0.0809\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0122 - mae: 0.0876 - val_loss: 0.0114 - val_mae: 0.0849\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0121 - mae: 0.0855 - val_loss: 0.0107 - val_mae: 0.0815\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0111 - mae: 0.0843 - val_loss: 0.0107 - val_mae: 0.0843\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0103 - mae: 0.0805 - val_loss: 0.0109 - val_mae: 0.0828\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0104 - mae: 0.0798 - val_loss: 0.0096 - val_mae: 0.0768\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0088 - mae: 0.0737 - val_loss: 0.0088 - val_mae: 0.0739\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0093 - mae: 0.0750 - val_loss: 0.0096 - val_mae: 0.0778\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0087 - mae: 0.0736 - val_loss: 0.0110 - val_mae: 0.0831\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0087 - mae: 0.0746 - val_loss: 0.0119 - val_mae: 0.0869\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0079 - mae: 0.0699 - val_loss: 0.0130 - val_mae: 0.0907\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0077 - mae: 0.0686 - val_loss: 0.0133 - val_mae: 0.0944\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0066 - mae: 0.0640 - val_loss: 0.0166 - val_mae: 0.1071\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0073 - mae: 0.0672 - val_loss: 0.0226 - val_mae: 0.1279\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0059 - mae: 0.0608 - val_loss: 0.0150 - val_mae: 0.1023\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0055 - mae: 0.0589 - val_loss: 0.0164 - val_mae: 0.1077\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0065 - mae: 0.0640 - val_loss: 0.0222 - val_mae: 0.1270\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0059 - mae: 0.0597 - val_loss: 0.0184 - val_mae: 0.1152\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0054 - mae: 0.0578 - val_loss: 0.0230 - val_mae: 0.1326\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0057 - mae: 0.0592 - val_loss: 0.0158 - val_mae: 0.1071\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0057 - mae: 0.0593 - val_loss: 0.0224 - val_mae: 0.1297\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0055 - mae: 0.0596 - val_loss: 0.0202 - val_mae: 0.1223\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0058 - mae: 0.0595 - val_loss: 0.0235 - val_mae: 0.1319\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0057 - mae: 0.0591 - val_loss: 0.0259 - val_mae: 0.1400\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0058 - mae: 0.0597 - val_loss: 0.0219 - val_mae: 0.1275\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0055 - mae: 0.0587 - val_loss: 0.0179 - val_mae: 0.1153\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0049 - mae: 0.0542 - val_loss: 0.0260 - val_mae: 0.1390\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 2, 'layers_type': 'LSTM', 'units': 160, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 7s 19ms/step - loss: 0.0285 - mae: 0.1281 - val_loss: 0.0163 - val_mae: 0.1019\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0161 - mae: 0.1011 - val_loss: 0.0141 - val_mae: 0.0944\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0178 - mae: 0.1059 - val_loss: 0.0141 - val_mae: 0.0944\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0154 - mae: 0.0994 - val_loss: 0.0137 - val_mae: 0.0937\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0170 - mae: 0.1027 - val_loss: 0.0145 - val_mae: 0.0959\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0165 - mae: 0.1007 - val_loss: 0.0159 - val_mae: 0.1009\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0145 - mae: 0.0949 - val_loss: 0.0212 - val_mae: 0.1186\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0151 - mae: 0.0987 - val_loss: 0.0105 - val_mae: 0.0816\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0127 - mae: 0.0891 - val_loss: 0.0232 - val_mae: 0.1244\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0112 - mae: 0.0851 - val_loss: 0.0336 - val_mae: 0.1545\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0099 - mae: 0.0789 - val_loss: 0.0481 - val_mae: 0.1859\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0100 - mae: 0.0800 - val_loss: 0.0434 - val_mae: 0.1749\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0088 - mae: 0.0738 - val_loss: 0.0577 - val_mae: 0.2047\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0093 - mae: 0.0774 - val_loss: 0.0568 - val_mae: 0.2039\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0094 - mae: 0.0769 - val_loss: 0.0767 - val_mae: 0.2405\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0087 - mae: 0.0745 - val_loss: 0.0455 - val_mae: 0.1796\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0088 - mae: 0.0723 - val_loss: 0.0665 - val_mae: 0.2257\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0096 - mae: 0.0764 - val_loss: 0.0542 - val_mae: 0.1978\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0085 - mae: 0.0725 - val_loss: 0.0688 - val_mae: 0.2297\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0077 - mae: 0.0686 - val_loss: 0.0547 - val_mae: 0.2043\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0079 - mae: 0.0702 - val_loss: 0.0838 - val_mae: 0.2530\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0080 - mae: 0.0705 - val_loss: 0.0655 - val_mae: 0.2218\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0071 - mae: 0.0664 - val_loss: 0.0811 - val_mae: 0.2525\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0080 - mae: 0.0709 - val_loss: 0.0553 - val_mae: 0.2028\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0069 - mae: 0.0649 - val_loss: 0.0715 - val_mae: 0.2325\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0068 - mae: 0.0655 - val_loss: 0.0703 - val_mae: 0.2302\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0075 - mae: 0.0675 - val_loss: 0.0757 - val_mae: 0.2387\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 3s 14ms/step - loss: 0.0072 - mae: 0.0668 - val_loss: 0.0649 - val_mae: 0.2185\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 3, 'layers_type': 'GRU', 'units': 10, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 8s 24ms/step - loss: 0.0889 - mae: 0.2188 - val_loss: 0.0113 - val_mae: 0.0831\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 4s 22ms/step - loss: 0.0086 - mae: 0.0734 - val_loss: 0.0090 - val_mae: 0.0748\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0066 - mae: 0.0643 - val_loss: 0.0078 - val_mae: 0.0701\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0062 - mae: 0.0637 - val_loss: 0.0073 - val_mae: 0.0675\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0060 - mae: 0.0613 - val_loss: 0.0061 - val_mae: 0.0614\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0051 - mae: 0.0557 - val_loss: 0.0054 - val_mae: 0.0573\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0047 - mae: 0.0545 - val_loss: 0.0050 - val_mae: 0.0545\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0045 - val_mae: 0.0520\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0051 - val_mae: 0.0580\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0042 - mae: 0.0510 - val_loss: 0.0041 - val_mae: 0.0503\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0040 - mae: 0.0492 - val_loss: 0.0041 - val_mae: 0.0508\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0044 - val_mae: 0.0504\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0036 - mae: 0.0466 - val_loss: 0.0041 - val_mae: 0.0498\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0042 - val_mae: 0.0510\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0040 - mae: 0.0491 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 4s 22ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0046 - val_mae: 0.0529\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0041 - val_mae: 0.0503\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0040 - val_mae: 0.0502\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0041 - mae: 0.0508 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0471 - val_loss: 0.0044 - val_mae: 0.0532\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0042 - mae: 0.0512 - val_loss: 0.0040 - val_mae: 0.0500\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0044 - val_mae: 0.0528\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0049 - val_mae: 0.0539\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0044 - val_mae: 0.0536\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0041 - val_mae: 0.0493\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0041 - val_mae: 0.0514\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0040 - val_mae: 0.0500\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 4s 22ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0037 - mae: 0.0480 - val_loss: 0.0042 - val_mae: 0.0521\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0041 - val_mae: 0.0510\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0035 - mae: 0.0466 - val_loss: 0.0044 - val_mae: 0.0508\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0037 - mae: 0.0484 - val_loss: 0.0039 - val_mae: 0.0488\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0041 - val_mae: 0.0499\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0494 - val_loss: 0.0043 - val_mae: 0.0501\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0041 - val_mae: 0.0509\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0474 - val_loss: 0.0039 - val_mae: 0.0484\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0040 - mae: 0.0504 - val_loss: 0.0041 - val_mae: 0.0513\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0040 - mae: 0.0487 - val_loss: 0.0042 - val_mae: 0.0515\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0043 - mae: 0.0512 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0043 - val_mae: 0.0521\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0038 - mae: 0.0487 - val_loss: 0.0048 - val_mae: 0.0563\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 4s 22ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0036 - mae: 0.0477 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0040 - val_mae: 0.0491\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0485\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0033 - mae: 0.0457 - val_loss: 0.0041 - val_mae: 0.0493\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0480 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0040 - val_mae: 0.0494\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0468 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 54/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0482 - val_loss: 0.0041 - val_mae: 0.0496\n",
      "Epoch 55/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0045 - val_mae: 0.0519\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 3, 'layers_type': 'GRU', 'units': 10, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 7s 20ms/step - loss: 0.0920 - mae: 0.2214 - val_loss: 0.0169 - val_mae: 0.1029\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0163 - mae: 0.1017 - val_loss: 0.0117 - val_mae: 0.0848\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0140 - mae: 0.0956 - val_loss: 0.0121 - val_mae: 0.0875\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0124 - mae: 0.0878 - val_loss: 0.0140 - val_mae: 0.0954\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 4s 23ms/step - loss: 0.0117 - mae: 0.0850 - val_loss: 0.0102 - val_mae: 0.0801\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0117 - mae: 0.0860 - val_loss: 0.0103 - val_mae: 0.0802\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0108 - mae: 0.0811 - val_loss: 0.0101 - val_mae: 0.0802\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0110 - mae: 0.0836 - val_loss: 0.0100 - val_mae: 0.0794\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0097 - mae: 0.0780 - val_loss: 0.0118 - val_mae: 0.0867\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0106 - mae: 0.0813 - val_loss: 0.0134 - val_mae: 0.0926\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0099 - mae: 0.0791 - val_loss: 0.0101 - val_mae: 0.0788\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0102 - mae: 0.0785 - val_loss: 0.0153 - val_mae: 0.0998\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0095 - mae: 0.0772 - val_loss: 0.0111 - val_mae: 0.0838\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0082 - mae: 0.0703 - val_loss: 0.0137 - val_mae: 0.0942\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0085 - mae: 0.0727 - val_loss: 0.0180 - val_mae: 0.1099\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0089 - mae: 0.0742 - val_loss: 0.0165 - val_mae: 0.1038\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0086 - mae: 0.0740 - val_loss: 0.0135 - val_mae: 0.0937\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0084 - mae: 0.0730 - val_loss: 0.0118 - val_mae: 0.0856\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0083 - mae: 0.0731 - val_loss: 0.0140 - val_mae: 0.0953\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 4s 23ms/step - loss: 0.0087 - mae: 0.0722 - val_loss: 0.0164 - val_mae: 0.1044\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0072 - mae: 0.0677 - val_loss: 0.0186 - val_mae: 0.1128\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0082 - mae: 0.0713 - val_loss: 0.0199 - val_mae: 0.1161\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0085 - mae: 0.0737 - val_loss: 0.0127 - val_mae: 0.0892\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0080 - mae: 0.0700 - val_loss: 0.0127 - val_mae: 0.0902\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0079 - mae: 0.0712 - val_loss: 0.0144 - val_mae: 0.0980\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0079 - mae: 0.0706 - val_loss: 0.0187 - val_mae: 0.1123\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0081 - mae: 0.0691 - val_loss: 0.0149 - val_mae: 0.0992\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0072 - mae: 0.0667 - val_loss: 0.0208 - val_mae: 0.1199\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 3, 'layers_type': 'GRU', 'units': 10, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 8s 20ms/step - loss: 0.0460 - mae: 0.1714 - val_loss: 0.0175 - val_mae: 0.1067\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0232 - mae: 0.1214 - val_loss: 0.0205 - val_mae: 0.1151\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0239 - mae: 0.1208 - val_loss: 0.0157 - val_mae: 0.1003\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0174 - mae: 0.1055 - val_loss: 0.0135 - val_mae: 0.0921\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0157 - mae: 0.0994 - val_loss: 0.0164 - val_mae: 0.1021\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 4s 23ms/step - loss: 0.0163 - mae: 0.1012 - val_loss: 0.0170 - val_mae: 0.1050\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 4s 22ms/step - loss: 0.0133 - mae: 0.0902 - val_loss: 0.0155 - val_mae: 0.1001\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0126 - mae: 0.0880 - val_loss: 0.0224 - val_mae: 0.1209\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0131 - mae: 0.0913 - val_loss: 0.0234 - val_mae: 0.1236\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0130 - mae: 0.0909 - val_loss: 0.0261 - val_mae: 0.1315\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0126 - mae: 0.0916 - val_loss: 0.0397 - val_mae: 0.1648\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0116 - mae: 0.0857 - val_loss: 0.0283 - val_mae: 0.1364\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0108 - mae: 0.0820 - val_loss: 0.0405 - val_mae: 0.1659\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0112 - mae: 0.0825 - val_loss: 0.0509 - val_mae: 0.1892\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0111 - mae: 0.0843 - val_loss: 0.0486 - val_mae: 0.1832\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0107 - mae: 0.0813 - val_loss: 0.0397 - val_mae: 0.1649\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0117 - mae: 0.0861 - val_loss: 0.0657 - val_mae: 0.2211\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0110 - mae: 0.0816 - val_loss: 0.0683 - val_mae: 0.2259\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0108 - mae: 0.0812 - val_loss: 0.0671 - val_mae: 0.2208\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0107 - mae: 0.0821 - val_loss: 0.0649 - val_mae: 0.2174\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 4s 23ms/step - loss: 0.0100 - mae: 0.0796 - val_loss: 0.0703 - val_mae: 0.2266\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0111 - mae: 0.0828 - val_loss: 0.0800 - val_mae: 0.2439\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0100 - mae: 0.0781 - val_loss: 0.0607 - val_mae: 0.2060\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0096 - mae: 0.0777 - val_loss: 0.0716 - val_mae: 0.2267\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 3, 'layers_type': 'GRU', 'units': 20, 'dropout': 0.0}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 8s 20ms/step - loss: 0.0473 - mae: 0.1466 - val_loss: 0.0095 - val_mae: 0.0762\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0074 - mae: 0.0697 - val_loss: 0.0081 - val_mae: 0.0713\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0059 - mae: 0.0605 - val_loss: 0.0062 - val_mae: 0.0623\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0050 - mae: 0.0559 - val_loss: 0.0056 - val_mae: 0.0592\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0044 - mae: 0.0520 - val_loss: 0.0047 - val_mae: 0.0542\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0485 - val_loss: 0.0041 - val_mae: 0.0499\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0040 - mae: 0.0498 - val_loss: 0.0042 - val_mae: 0.0513\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0042 - mae: 0.0513 - val_loss: 0.0043 - val_mae: 0.0524\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0493 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0041 - mae: 0.0501 - val_loss: 0.0043 - val_mae: 0.0501\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0041 - val_mae: 0.0497\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0042 - val_mae: 0.0508\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 4s 22ms/step - loss: 0.0042 - mae: 0.0509 - val_loss: 0.0043 - val_mae: 0.0509\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0040 - mae: 0.0491 - val_loss: 0.0044 - val_mae: 0.0513\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0041 - mae: 0.0510 - val_loss: 0.0041 - val_mae: 0.0488\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0042 - mae: 0.0503 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0036 - mae: 0.0467 - val_loss: 0.0044 - val_mae: 0.0532\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0496 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0479 - val_loss: 0.0042 - val_mae: 0.0494\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0481 - val_loss: 0.0042 - val_mae: 0.0502\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0042 - mae: 0.0511 - val_loss: 0.0043 - val_mae: 0.0502\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0036 - mae: 0.0471 - val_loss: 0.0064 - val_mae: 0.0659\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0041 - mae: 0.0508 - val_loss: 0.0040 - val_mae: 0.0499\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0041 - mae: 0.0501 - val_loss: 0.0041 - val_mae: 0.0507\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0037 - mae: 0.0479 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 28/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0041 - mae: 0.0503 - val_loss: 0.0041 - val_mae: 0.0500\n",
      "Epoch 29/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0038 - mae: 0.0484 - val_loss: 0.0044 - val_mae: 0.0532\n",
      "Epoch 30/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0040 - mae: 0.0494 - val_loss: 0.0040 - val_mae: 0.0492\n",
      "Epoch 31/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0492 - val_loss: 0.0040 - val_mae: 0.0487\n",
      "Epoch 32/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0491 - val_loss: 0.0043 - val_mae: 0.0520\n",
      "Epoch 33/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0043 - val_mae: 0.0509\n",
      "Epoch 34/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0035 - mae: 0.0465 - val_loss: 0.0045 - val_mae: 0.0522\n",
      "Epoch 35/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 36/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0493 - val_loss: 0.0043 - val_mae: 0.0527\n",
      "Epoch 37/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0043 - val_mae: 0.0517\n",
      "Epoch 38/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 39/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0041 - val_mae: 0.0499\n",
      "Epoch 40/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0483 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 41/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0486 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 42/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0041 - mae: 0.0502 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 43/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0037 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0498\n",
      "Epoch 44/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0040 - val_mae: 0.0493\n",
      "Epoch 45/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 46/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0047 - val_mae: 0.0534\n",
      "Epoch 47/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0493\n",
      "Epoch 48/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0040 - val_mae: 0.0503\n",
      "Epoch 49/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0038 - mae: 0.0482 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 50/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0486\n",
      "Epoch 51/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0040 - mae: 0.0497 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 52/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0041 - val_mae: 0.0500\n",
      "Epoch 53/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0041 - mae: 0.0508 - val_loss: 0.0041 - val_mae: 0.0513\n",
      "Epoch 54/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0487 - val_loss: 0.0039 - val_mae: 0.0483\n",
      "Epoch 55/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0042 - val_mae: 0.0514\n",
      "Epoch 56/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0040 - val_mae: 0.0488\n",
      "Epoch 57/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0490 - val_loss: 0.0041 - val_mae: 0.0498\n",
      "Epoch 58/250\n",
      "186/186 [==============================] - 4s 22ms/step - loss: 0.0039 - mae: 0.0489 - val_loss: 0.0042 - val_mae: 0.0500\n",
      "Epoch 59/250\n",
      "186/186 [==============================] - 4s 21ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0046 - val_mae: 0.0552\n",
      "Epoch 60/250\n",
      "186/186 [==============================] - 4s 20ms/step - loss: 0.0038 - mae: 0.0491 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 61/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0041 - val_mae: 0.0492\n",
      "Epoch 62/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0039 - mae: 0.0483 - val_loss: 0.0040 - val_mae: 0.0490\n",
      "Epoch 63/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0041 - mae: 0.0509 - val_loss: 0.0043 - val_mae: 0.0504\n",
      "Epoch 64/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0041 - mae: 0.0506 - val_loss: 0.0042 - val_mae: 0.0518\n",
      "Epoch 65/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 66/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0035 - mae: 0.0461 - val_loss: 0.0039 - val_mae: 0.0491\n",
      "Epoch 67/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0043 - val_mae: 0.0501\n",
      "Epoch 68/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0477 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 69/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0039 - mae: 0.0488 - val_loss: 0.0040 - val_mae: 0.0496\n",
      "Epoch 70/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0036 - mae: 0.0478 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 71/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 72/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0042 - val_mae: 0.0502\n",
      "Epoch 73/250\n",
      "186/186 [==============================] - 3s 18ms/step - loss: 0.0040 - mae: 0.0496 - val_loss: 0.0039 - val_mae: 0.0482\n",
      "Epoch 74/250\n",
      "186/186 [==============================] - 4s 22ms/step - loss: 0.0040 - mae: 0.0498 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 3, 'layers_type': 'GRU', 'units': 20, 'dropout': 0.25}\n",
      "Epoch 1/250\n",
      "186/186 [==============================] - 9s 20ms/step - loss: 0.0501 - mae: 0.1601 - val_loss: 0.0122 - val_mae: 0.0867\n",
      "Epoch 2/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0139 - mae: 0.0941 - val_loss: 0.0102 - val_mae: 0.0789\n",
      "Epoch 3/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0121 - mae: 0.0878 - val_loss: 0.0110 - val_mae: 0.0823\n",
      "Epoch 4/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0111 - mae: 0.0835 - val_loss: 0.0098 - val_mae: 0.0780\n",
      "Epoch 5/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0100 - mae: 0.0788 - val_loss: 0.0106 - val_mae: 0.0823\n",
      "Epoch 6/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0103 - mae: 0.0802 - val_loss: 0.0120 - val_mae: 0.0881\n",
      "Epoch 7/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0109 - mae: 0.0813 - val_loss: 0.0095 - val_mae: 0.0764\n",
      "Epoch 8/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0100 - mae: 0.0790 - val_loss: 0.0125 - val_mae: 0.0891\n",
      "Epoch 9/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0112 - mae: 0.0830 - val_loss: 0.0105 - val_mae: 0.0806\n",
      "Epoch 10/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0091 - mae: 0.0756 - val_loss: 0.0116 - val_mae: 0.0859\n",
      "Epoch 11/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0095 - mae: 0.0761 - val_loss: 0.0162 - val_mae: 0.1039\n",
      "Epoch 12/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0089 - mae: 0.0742 - val_loss: 0.0117 - val_mae: 0.0854\n",
      "Epoch 13/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0078 - mae: 0.0703 - val_loss: 0.0138 - val_mae: 0.0948\n",
      "Epoch 14/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0088 - mae: 0.0739 - val_loss: 0.0133 - val_mae: 0.0923\n",
      "Epoch 15/250\n",
      "186/186 [==============================] - 4s 19ms/step - loss: 0.0079 - mae: 0.0699 - val_loss: 0.0199 - val_mae: 0.1174\n",
      "Epoch 16/250\n",
      "186/186 [==============================] - 4s 23ms/step - loss: 0.0075 - mae: 0.0681 - val_loss: 0.0172 - val_mae: 0.1079\n",
      "Epoch 17/250\n",
      "186/186 [==============================] - 4s 22ms/step - loss: 0.0083 - mae: 0.0719 - val_loss: 0.0140 - val_mae: 0.0960\n",
      "Epoch 18/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0078 - mae: 0.0688 - val_loss: 0.0251 - val_mae: 0.1350\n",
      "Epoch 19/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0079 - mae: 0.0711 - val_loss: 0.0157 - val_mae: 0.1028\n",
      "Epoch 20/250\n",
      "186/186 [==============================] - 3s 17ms/step - loss: 0.0076 - mae: 0.0694 - val_loss: 0.0215 - val_mae: 0.1219\n",
      "Epoch 21/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0077 - mae: 0.0690 - val_loss: 0.0186 - val_mae: 0.1134\n",
      "Epoch 22/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0066 - mae: 0.0643 - val_loss: 0.0228 - val_mae: 0.1282\n",
      "Epoch 23/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0065 - mae: 0.0629 - val_loss: 0.0230 - val_mae: 0.1280\n",
      "Epoch 24/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0066 - mae: 0.0633 - val_loss: 0.0169 - val_mae: 0.1073\n",
      "Epoch 25/250\n",
      "186/186 [==============================] - 3s 16ms/step - loss: 0.0062 - mae: 0.0630 - val_loss: 0.0189 - val_mae: 0.1140\n",
      "Epoch 26/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0065 - mae: 0.0639 - val_loss: 0.0156 - val_mae: 0.1019\n",
      "Epoch 27/250\n",
      "186/186 [==============================] - 3s 15ms/step - loss: 0.0063 - mae: 0.0623 - val_loss: 0.0237 - val_mae: 0.1303\n",
      "\n",
      "Now Training \n",
      "{'length': 90, 'layers_num': 3, 'layers_type': 'GRU', 'units': 20, 'dropout': 0.5}\n",
      "Epoch 1/250\n",
      " 13/186 [=>............................] - ETA: 2s - loss: 0.2753 - mae: 0.4478"
     ]
    }
   ],
   "source": [
    "#Hyperparameters\n",
    "length = [1, 5, 10, 30, 90, 180, 365]\n",
    "layers_num = [1, 2, 3]\n",
    "layers_type = ['GRU', 'LSTM']\n",
    "units = [10, 20, 40, 80, 160] \n",
    "dropout = [0.0, 0.25, 0.5]\n",
    "\n",
    "#get every combo\n",
    "grid_table = gridTableGen(length, layers_num, layers_type, units, dropout)\n",
    "print('\\nN combos: {}'.format(len(grid_table)))\n",
    "\n",
    "#search\n",
    "results = gridSearch(grid_table, temp_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKKEor2UqjkC"
   },
   "source": [
    "## Analyse the Grid Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1621886180450,
     "user": {
      "displayName": "1990JAF",
      "photoUrl": "",
      "userId": "13601147066600634770"
     },
     "user_tz": -60
    },
    "id": "YlsPbt8oDqrd"
   },
   "outputs": [],
   "source": [
    "#load it from drive\n",
    "gs = pd.read_csv('results_table_temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1621886205048,
     "user": {
      "displayName": "1990JAF",
      "photoUrl": "",
      "userId": "13601147066600634770"
     },
     "user_tz": -60
    },
    "id": "yy4HTUiN8jdK",
    "outputId": "462be142-0f0f-46bd-d2bd-636b37a7010f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "gs.groupby('length')['val_mae'].mean().plot(kind='bar', title='mean'); plt.show()\n",
    "gs.groupby('layers_num')['val_mae'].mean().plot(kind='bar', title='mean'); plt.show()\n",
    "gs.groupby('layers_type')['val_mae'].mean().plot(kind='bar', title='mean'); plt.show()\n",
    "gs.groupby('units')['val_mae'].mean().plot(kind='bar', title='mean'); plt.show()\n",
    "gs.groupby('dropout')['val_mae'].mean().plot(kind='bar', title='mean'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dq_c9UL_qdBv"
   },
   "source": [
    "Whilst the MAE isnt much better than the baseline, the model is picking up a trend.\n",
    "\n",
    "We see this by its increasing performance as we feed it longer sequences. \n",
    "\n",
    "\n",
    "The model is learning to predict the future better by being fed more history at a time.\n",
    "\n",
    "Dropout does not improve the model performance. Its not often dropout is used in RNN networks, they tend to overfit for other reasons.\n",
    "\n",
    "LSTM is just slightly better than GRU.\n",
    "Increasing the number of RNN layers does not improve the predictive power of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baxGqm1-9N43"
   },
   "source": [
    "## Recreate the best model and compare against test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1621886514316,
     "user": {
      "displayName": "1990JAF",
      "photoUrl": "",
      "userId": "13601147066600634770"
     },
     "user_tz": -60
    },
    "id": "xgaP2nND9GFo",
    "outputId": "b8b703af-6055-4026-e4ec-83e48867ce11"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "length             90\n",
       "layers_num          1\n",
       "layers_type       GRU\n",
       "units             160\n",
       "dropout             0\n",
       "loss           0.0036\n",
       "mae            0.0473\n",
       "val_loss       0.0037\n",
       "val_mae        0.0471\n",
       "epochs             95\n",
       "Name: 372, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_params = gs.sort_values('val_mae').iloc[0]\n",
    "best_model_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71221,
     "status": "ok",
     "timestamp": 1621886737548,
     "user": {
      "displayName": "1990JAF",
      "photoUrl": "",
      "userId": "13601147066600634770"
     },
     "user_tz": -60
    },
    "id": "l2P2LHIs90vP",
    "outputId": "e63dc3f3-0721-4687-85cd-78cbb5c8558b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "186/186 [==============================] - 34s 9ms/step - loss: 0.0410 - mae: 0.1313 - val_loss: 0.0074 - val_mae: 0.0672\n",
      "Epoch 2/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0063 - mae: 0.0630 - val_loss: 0.0059 - val_mae: 0.0598\n",
      "Epoch 3/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0049 - mae: 0.0562 - val_loss: 0.0052 - val_mae: 0.0561\n",
      "Epoch 4/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0045 - mae: 0.0533 - val_loss: 0.0054 - val_mae: 0.0571\n",
      "Epoch 5/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0042 - mae: 0.0516 - val_loss: 0.0049 - val_mae: 0.0563\n",
      "Epoch 6/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0053 - val_mae: 0.0590\n",
      "Epoch 7/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0042 - mae: 0.0507 - val_loss: 0.0041 - val_mae: 0.0508\n",
      "Epoch 8/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0040 - mae: 0.0500 - val_loss: 0.0056 - val_mae: 0.0587\n",
      "Epoch 9/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0041 - val_mae: 0.0508\n",
      "Epoch 10/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0037 - mae: 0.0472 - val_loss: 0.0041 - val_mae: 0.0491\n",
      "Epoch 11/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0040 - val_mae: 0.0498\n",
      "Epoch 12/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0037 - mae: 0.0476 - val_loss: 0.0040 - val_mae: 0.0484\n",
      "Epoch 13/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0039 - mae: 0.0481 - val_loss: 0.0046 - val_mae: 0.0527\n",
      "Epoch 14/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0039 - mae: 0.0495 - val_loss: 0.0040 - val_mae: 0.0495\n",
      "Epoch 15/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0038 - mae: 0.0485 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 16/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0041 - mae: 0.0500 - val_loss: 0.0040 - val_mae: 0.0489\n",
      "Epoch 17/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0037 - mae: 0.0475 - val_loss: 0.0040 - val_mae: 0.0503\n",
      "Epoch 18/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0041 - mae: 0.0505 - val_loss: 0.0039 - val_mae: 0.0485\n",
      "Epoch 19/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0039 - mae: 0.0485 - val_loss: 0.0039 - val_mae: 0.0487\n",
      "Epoch 20/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0037 - mae: 0.0473 - val_loss: 0.0040 - val_mae: 0.0486\n",
      "Epoch 21/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0040 - mae: 0.0499 - val_loss: 0.0042 - val_mae: 0.0518\n",
      "Epoch 22/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0036 - mae: 0.0478 - val_loss: 0.0041 - val_mae: 0.0496\n",
      "Epoch 23/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0039 - mae: 0.0484 - val_loss: 0.0042 - val_mae: 0.0521\n",
      "Epoch 24/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0038 - mae: 0.0480 - val_loss: 0.0042 - val_mae: 0.0516\n",
      "Epoch 25/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0038 - mae: 0.0488 - val_loss: 0.0041 - val_mae: 0.0498\n",
      "Epoch 26/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0037 - mae: 0.0478 - val_loss: 0.0041 - val_mae: 0.0495\n",
      "Epoch 27/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0038 - mae: 0.0486 - val_loss: 0.0046 - val_mae: 0.0550\n",
      "Epoch 28/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0036 - mae: 0.0473 - val_loss: 0.0041 - val_mae: 0.0504\n",
      "Epoch 29/120\n",
      "186/186 [==============================] - 1s 6ms/step - loss: 0.0038 - mae: 0.0477 - val_loss: 0.0040 - val_mae: 0.0502\n"
     ]
    }
   ],
   "source": [
    "best_model = BuildModel(model_name='best_temp_model.h5', length=90, layers_num=1,\\\n",
    "                        layers_type='GRU', units=160, dropout=0, epochs=120, batch_size=10,\\\n",
    "                        patience=10)\n",
    "\n",
    "best_model.setupData(temp_train)\n",
    "best_model.fitModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 938,
     "status": "ok",
     "timestamp": 1621886786930,
     "user": {
      "displayName": "1990JAF",
      "photoUrl": "",
      "userId": "13601147066600634770"
     },
     "user_tz": -60
    },
    "id": "HFZGpA-b-oVV"
   },
   "outputs": [],
   "source": [
    "#load best performer\n",
    "best_model.loadModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "executionInfo": {
     "elapsed": 897,
     "status": "ok",
     "timestamp": 1621886901644,
     "user": {
      "displayName": "1990JAF",
      "photoUrl": "",
      "userId": "13601147066600634770"
     },
     "user_tz": -60
    },
    "id": "MJFcWmP-_Fi2",
    "outputId": "0295160e-1a0c-4458-e4b3-c3f923f88b67"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predict a week\n",
    "week_pred = best_model.predAhead(7)\n",
    "\n",
    "#plot against test week\n",
    "best_model.plotPreds(week_pred, temp_test, ylabel='temp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jnO8qhM_lvW"
   },
   "source": [
    "Thats really not much better than just predicting the last point in the series like the baseline did. \n",
    "\n",
    "There is some variation here since the model did appreciate longer series being fed into it. So it has performed just slightly better than the baseline.\n",
    "\n",
    "We can do more! I suspect that the series was just too erratic for our model to fit to.\n",
    "\n",
    "In the next notebook we will add a new hyperparameter to the model. This will smoove the time series that the model is fed. Maybe then, it will be able to lockdown the signal and ignore the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J-oL3LMs_hkA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOeQBLCqLCSC0XV8+9Uq3Hc",
   "collapsed_sections": [],
   "mount_file_id": "1k4rijeMVX8Aobk96hjSG3s8sSJbQGMiU",
   "name": "model_build.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
